{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyO/aT0g+sRBjlv2JkU7cdvJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7oNH2OZUsw8B"},"outputs":[],"source":["import pandas as pd\n","import xml.etree.ElementTree as ET\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define file paths in Google Drive\n","xml_file_path = \"/content/drive/My Drive/German Pol Speeches/Bundesregierung.xml\"\n","qids_file_path = \"/content/drive/My Drive/German Pol Speeches/QIDs.csv\"\n","\n","# Read QIDs CSV file\n","qids = pd.read_csv(qids_file_path, encoding=\"ISO-8859-1\", delimiter=\";\")\n","\n","# Parse XML file\n","tree = ET.parse(xml_file_path)\n","root = tree.getroot()\n","\n","# Extract data from XML into a DataFrame\n","data = []\n","for text_node in root.findall(\"text\"):\n","    person = text_node.get(\"person\", \"\")\n","    titel = text_node.get(\"titel\", \"\")\n","    datum = text_node.get(\"datum\", \"\")\n","    ort = text_node.get(\"ort\", \"\")\n","    untertitel = text_node.get(\"untertitel\", \"\")\n","    url = text_node.get(\"url\", \"\")\n","    anrede = text_node.get(\"anrede\", \"\")\n","\n","    # Extract 'rohtext'\n","    rohtext_node = text_node.find(\"rohtext\")\n","    rohtext = rohtext_node.text if rohtext_node is not None else \"\"\n","\n","    data.append([person, titel, datum, ort, untertitel, url, anrede, rohtext])\n","\n","# Convert extracted XML data to a Pandas DataFrame\n","df = pd.DataFrame(data, columns=[\"Person\", \"Titel\", \"Datum\", \"Ort\", \"Untertitel\", \"URL\", \"Anrede\", \"Rohtext\"])\n","\n","# Standardize names (trim spaces and remove multiple spaces)\n","df[\"Person\"] = df[\"Person\"].str.strip().str.replace(r\"\\s+\", \" \", regex=True)\n","qids[\"person\"] = qids[\"person\"].str.strip().str.replace(r\"\\s+\", \" \", regex=True)\n","\n","# Merge the speech dataset with QIDs\n","merged_df = pd.merge(df, qids, left_on=\"Person\", right_on=\"person\", how=\"outer\")\n","\n","# Save the merged dataset to Google Drive\n","output_file = \"/content/drive/My Drive/German Pol Speeches/Merged_Speeches_QIDs.csv\"\n","merged_df.to_csv(output_file, index=False)\n","\n","print(f\"âœ… Merged dataset saved to Google Drive: {output_file}\")\n"]},{"cell_type":"code","source":["# Display the first 5 rows of the merged dataset\n","merged_df.head()\n"],"metadata":{"id":"JtN5sCcBxb5E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","# Drop rows where 'sex' is NaN and reassign properly\n","merged_df = merged_df.loc[merged_df[\"sex\"].notna()].copy()\n","\n","# Convert 'sex' to integer binary (0 or 1)\n","merged_df[\"sex\"] = merged_df[\"sex\"].astype(int)\n","\n","\n","# Function to split text into sentences\n","def split_text(text):\n","    return re.split(r'(?<=[.!?])\\s+', text.strip()) if isinstance(text, str) else []\n","\n","# Define words referring to women in German\n","women_keywords = [\n","    \"Frau\", \"Frauen\", \"MÃ¤dchen\", \"MÃ¤del\", \"Dame\", \"Damen\", \"Weib\", \"Weiber\", \"Mutter\", \"MÃ¼tter\",\n","    \"Schwester\", \"Schwestern\", \"Tochter\", \"TÃ¶chter\", \"Ehefrau\", \"Ehefrauen\", \"Gattin\", \"GÃ¶ttin\",\n","    \"Weiblichkeit\", \"weiblich\", \"MÃ¼tterlichkeit\", \"MÃ¤dchenhaft\", \"Frauenrecht\", \"Frauenrechte\",\n","    \"Frauenbewegung\", \"Feministin\", \"Feminismus\", \"Geschlechtergerechtigkeit\"\n","]\n","\n","# Initialize a new DataFrame for sentence-level data\n","sentence_data = []\n","\n","# Iterate through each speech and split into sentences\n","for idx, row in merged_df.iterrows():\n","    sentences = split_text(row[\"Rohtext\"])  # Split text into sentences\n","    speech_id = f\"{idx}\"  # Create an identifier for the speech\n","\n","    for sentence_num, sentence in enumerate(sentences, start=1):\n","        sentence_id = f\"{speech_id}_{sentence_num}\"  # Unique sentence identifier\n","\n","        # Check if sentence contains any women-related words\n","        contains_women = any(word in sentence for word in women_keywords)\n","\n","        # Append to new dataset (excluding Rohtext to save space)\n","        sentence_data.append({\n","            \"speech_id\": speech_id,\n","            \"sentence_id\": sentence_id,\n","            \"sentence\": sentence.strip(),\n","            \"sex\": row[\"sex\"],\n","            \"party\": row[\"party\"],\n","            \"Datum\": row[\"Datum\"],\n","            \"Ort\": row[\"Ort\"],\n","            \"Titel\": row[\"Titel\"],\n","            \"Untertitel\": row[\"Untertitel\"],\n","            \"URL\": row[\"URL\"],\n","            \"Anrede\": row[\"Anrede\"],\n","            \"women\": contains_women  # True if sentence references women, else False\n","        })\n","\n","# Convert to DataFrame\n","sentence_df = pd.DataFrame(sentence_data)\n","\n","# Save the new structured dataset to Google Drive\n","output_file = \"/content/drive/My Drive/German Pol Speeches/Sentence_Level_Dataset.csv\"\n","sentence_df.to_csv(output_file, index=False)\n","\n","\n","\n","print(f\"âœ… Process complete! Sentence-level dataset saved to: {output_file}\")\n"],"metadata":{"id":"mBC_wYxFy4Eh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers torch\n"],"metadata":{"id":"-_5I-dOY4pQJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers datasets torch scikit-learn\n"],"metadata":{"id":"2z379E3n7SK2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","import json\n","from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n","from datasets import Dataset\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Disable wandb\n","import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","# Define file paths\n","dataset_path = \"/content/drive/MyDrive/complete_dataset_with_claims.csv\"\n","best_params_path = \"/content/drive/MyDrive/best_params.json\"\n","save_model_path = \"/content/drive/MyDrive/final_model\"\n","\n","# Load dataset\n","df = pd.read_csv(dataset_path)\n","\n","# Load best hyperparameters\n","with open(best_params_path, \"r\") as f:\n","    best_params = json.load(f)\n","\n","# Ensure correct column names\n","text_column = \"sentences\"  # Use the correct column name\n","label_column = \"claim\"  # Label column remains the same\n","\n","# Ensure necessary columns exist\n","if text_column not in df.columns or label_column not in df.columns:\n","    raise ValueError(f\"Dataset must contain '{text_column}' (text) and '{label_column}' (label). Found columns: {df.columns}\")\n","\n","# Convert \"claim\" to integer labels (0 or 1)\n","df[label_column] = df[label_column].astype(int)\n","\n","# Split data into training and test sets\n","train_texts, val_texts, train_labels, val_labels = train_test_split(\n","    df[text_column].tolist(), df[label_column].tolist(), test_size=0.1, random_state=42\n",")\n","\n","# Load multilingual BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n","\n","# Tokenize the dataset\n","def tokenize_function(examples):\n","    return tokenizer(examples[text_column], padding=\"max_length\", truncation=True, max_length=512)\n","\n","# Convert dataset to Hugging Face Dataset format\n","train_dataset = Dataset.from_dict({text_column: train_texts, \"label\": train_labels}).map(tokenize_function, batched=True)\n","val_dataset = Dataset.from_dict({text_column: val_texts, \"label\": val_labels}).map(tokenize_function, batched=True)\n","\n","# Load pre-trained multilingual BERT model\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n","\n","# Define training arguments using best hyperparameters\n","training_args = TrainingArguments(\n","    output_dir=\"/content/output\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=best_params[\"learning_rate\"],\n","    per_device_train_batch_size=best_params[\"batch_size\"],\n","    per_device_eval_batch_size=best_params[\"batch_size\"],\n","    num_train_epochs=best_params[\"epochs\"],\n","    weight_decay=best_params[\"weight_decay\"],\n","    logging_dir=\"/content/logs\",\n","    logging_steps=100,\n","    save_total_limit=2\n",")\n","\n","# Create Trainer instance\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset\n",")\n","\n","# Train the model (No wandb!)\n","trainer.train()\n","\n","# Save the model & tokenizer to Google Drive\n","trainer.save_model(save_model_path)\n","tokenizer.save_pretrained(save_model_path)\n","\n","print(f\" Training complete! Model saved to: {save_model_path}\")\n"],"metadata":{"id":"5GYwoT7W7cjr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Count the number of claims (label == 1)\n","num_claims = df[\"claim\"].sum()\n","\n","print(f\"Number of claims found: {num_claims}\")\n"],"metadata":{"id":"ZYtgz-TeLz0B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from google.colab import drive\n","from IPython.display import display\n","\n","# ðŸš€ Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define paths\n","model_path = \"/content/drive/My Drive/final_model\"  # Trained BERT model\n","sentence_file = \"/content/drive/My Drive/German Pol Speeches/Sentence_Level_Dataset.csv\"  # Sentence dataset\n","output_file = \"/content/drive/My Drive/German Pol Speeches/Classified_Sentences.csv\"  # Save classification results\n","\n","# Load the dataset\n","sentence_df = pd.read_csv(sentence_file)\n","\n","# Ensure \"women\" column exists\n","if \"women\" not in sentence_df.columns:\n","    raise ValueError(f\"Dataset must contain a 'women' column. Found columns: {sentence_df.columns}\")\n","\n","# Load trained BERT model and tokenizer\n","tokenizer = BertTokenizer.from_pretrained(model_path)\n","model = BertForSequenceClassification.from_pretrained(model_path)\n","model.eval()  # Set model to evaluation mode\n","\n","# Filter sentences that reference women\n","women_sentences = sentence_df[sentence_df[\"women\"] == True].copy()\n","\n","# Function to classify sentences\n","def classify_claims(sentences):\n","    predictions = []\n","    with torch.no_grad():\n","        for sentence in sentences:\n","            inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n","            outputs = model(**inputs)\n","            logits = outputs.logits\n","            probs = torch.nn.functional.softmax(logits, dim=-1)\n","            predicted_class = torch.argmax(probs, dim=-1).item()  # Get predicted class (0 or 1)\n","            predictions.append(predicted_class)\n","    return predictions\n","\n","# Apply classification\n","women_sentences[\"claim\"] = classify_claims(women_sentences[\"sentence\"].tolist())\n","\n","# Merge classification results back into the main dataset\n","sentence_df.loc[sentence_df[\"women\"] == True, \"claim\"] = women_sentences[\"claim\"]\n","\n","# Convert \"claim\" column to binary format (0 or 1)\n","sentence_df[\"claim\"] = sentence_df[\"claim\"].fillna(0).astype(int)\n","\n","# Count the number of TRUE (1) values in \"claim\"\n","num_claims = sentence_df[\"claim\"].sum()\n","print(f\"Total 'TRUE' values in claim: {num_claims}\")\n","\n","# Save the updated dataset\n","sentence_df.to_csv(output_file, index=False)\n","\n","print(f\"Classified dataset saved to: {output_file}\")\n","\n","# Display first few rows of the classified dataset\n","display(sentence_df.head())\n"],"metadata":{"id":"aAiuJssb4vKr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","#Define file paths\n","sentence_file = \"/content/drive/My Drive/German Pol Speeches/Sentence_Level_Dataset.csv\"\n","classified_file = \"/content/drive/My Drive/German Pol Speeches/Classified_Sentences.csv\"\n","output_summary_file = \"/content/drive/My Drive/German Pol Speeches/Speech_Level_Summary.csv\"\n","\n","# Load datasets with low_memory=False to avoid warnings\n","df_sentences = pd.read_csv(sentence_file, low_memory=False)\n","df_classified = pd.read_csv(classified_file, low_memory=False)\n","\n","# Ensure necessary columns exist\n","if \"speech_id\" not in df_sentences.columns or \"sentence\" not in df_sentences.columns:\n","    raise ValueError(f\"Sentence dataset must contain 'speech_id' and 'sentence' columns. Found: {df_sentences.columns}\")\n","\n","if \"speech_id\" not in df_classified.columns or \"sentence_id\" not in df_classified.columns or \"claim\" not in df_classified.columns:\n","    raise ValueError(f\"Classified dataset must contain 'speech_id', 'sentence_id', and 'claim' columns. Found: {df_classified.columns}\")\n","\n","# Merge claim data into sentence dataset\n","df_merged = df_sentences.merge(df_classified[[\"speech_id\", \"sentence_id\", \"claim\"]], on=[\"speech_id\", \"sentence_id\"], how=\"left\")\n","\n","# Convert 'claim' to numeric (defaulting NaN to 0)\n","df_merged[\"claim\"] = pd.to_numeric(df_merged[\"claim\"], errors=\"coerce\").fillna(0).astype(int)\n","\n","# Select all columns except \"sentence_id\" and \"sentence\" for grouping\n","metadata_columns = [col for col in df_merged.columns if col not in [\"sentence_id\", \"sentence\", \"claim\"]]\n","\n","# Aggregate by speech_id, keeping claim values\n","speech_summary = df_merged.groupby(\"speech_id\", as_index=False).agg({\n","    **{col: \"first\" for col in metadata_columns},  # Keep first occurrence of metadata columns\n","    \"sentence\": \" \".join,  # Concatenate all sentences into a single string\n","    \"claim\": \"sum\"  # Sum up claims per speech\n","})\n","\n","# Save summarized dataset\n","speech_summary.to_csv(output_summary_file, index=False)\n","\n","print(f\"Speech-level summary saved to: {output_summary_file}\")\n","\n","# Display first few rows\n","from IPython.display import display\n","display(speech_summary.head())\n"],"metadata":{"id":"6spGWTtBWyNz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# âœ… Calculate the total number of claims in the dataset\n","total_claims = speech_summary[\"claim\"].sum()\n","\n","print(f\"Total sum of claim for the whole dataset: {total_claims}\")\n"],"metadata":{"id":"Kdy-hRMqYMdd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add claimbinary column (1 if claim > 0, else 0)\n","speech_summary[\"claimbinary\"] = (speech_summary[\"claim\"] > 0).astype(int)\n","\n","# Calculate total sum of claims\n","total_claims = speech_summary[\"claim\"].sum()\n","print(f\"Total sum of claim for the whole dataset: {total_claims}\")\n","\n","# Save updated speech summary\n","output_summary_file = \"/content/drive/My Drive/German Pol Speeches/Speech_Level_Summary.csv\"\n","speech_summary.to_csv(output_summary_file, index=False)\n","\n","print(f\"Updated speech-level summary saved to: {output_summary_file}\")\n","\n","# Display first few rows\n","from IPython.display import display\n","display(speech_summary.head())\n"],"metadata":{"id":"dafZEPGuYfv7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Count the number of speeches where claimbinary is 1\n","num_speeches_with_claims = speech_summary[\"claimbinary\"].sum()\n","\n","print(f\"Number of speeches where claimbinary is 1: {num_speeches_with_claims}\")\n","\n"],"metadata":{"id":"a7KAyYJ0T_o2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Load the summarized speech dataset from Google Drive\n","output_summary_file = \"/content/drive/My Drive/German Pol Speeches/Speech_Level_Summary.csv\"\n","speech_summary = pd.read_csv(output_summary_file)\n","\n","# Ensure \"Datum\" is in datetime format\n","speech_summary[\"Datum\"] = pd.to_datetime(speech_summary[\"Datum\"], errors=\"coerce\")\n","\n","# Extract year from the date\n","speech_summary[\"year\"] = speech_summary[\"Datum\"].dt.year\n","\n","# Group by year and sex, counting speeches where claimbinary == 1\n","yearly_claims = speech_summary[speech_summary[\"claimbinary\"] == 1].groupby([\"year\", \"sex\"]).size().reset_index(name=\"count\")\n","\n","# Define custom colors and labels\n","colors = {0: \"#003399\", 1: \"#FFCC00\"}  # Men (blue), Women (yellow)\n","labels = {0: \"Men\", 1: \"Women\"}  # Replacing \"Sex 0\" with \"Men\" and \"Sex 1\" with \"Women\"\n","\n","# Plot the number of speeches with claims over time, separated by sex\n","plt.figure(figsize=(10, 6))\n","\n","for sex_value in yearly_claims[\"sex\"].unique():\n","    subset = yearly_claims[yearly_claims[\"sex\"] == sex_value]\n","    plt.plot(subset[\"year\"], subset[\"count\"], marker=\"o\", label=labels[sex_value], color=colors[sex_value])\n","\n","plt.xlabel(\"Year\")\n","plt.ylabel(\"Number of Speeches with Claims\")\n","plt.title(\"Speeches with Claims Over Time by Sex\")\n","plt.legend(title=\"Speaker Sex\")\n","plt.show()\n"],"metadata":{"id":"ElOHsNYvY2ta"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Neuer Abschnitt"],"metadata":{"id":"khTb5DvZKUVS"}},{"cell_type":"code","source":["import pandas as pd\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Load the dataset from Google Drive\n","output_summary_file = \"/content/drive/My Drive/German Pol Speeches/Speech_Level_Summary.csv\"\n","speech_summary = pd.read_csv(output_summary_file)\n","\n","# Define party replacements\n","party_replacements = {\n","    \"spd\": \"PES\",\n","    \"cdu\": \"EPP\",\n","    \"grÃ¼ne\": \"EGP\",\n","    \"fdp\": \"ALDE\"\n","}\n","\n","# Replace values in \"party\" column\n","speech_summary[\"party\"] = speech_summary[\"party\"].str.lower().map(party_replacements).fillna(speech_summary[\"party\"])\n","\n","# Save the updated dataset back to Google Drive\n","updated_summary_file = \"/content/drive/My Drive/German Pol Speeches/Speech_Level_Summary_Updated.csv\"\n","speech_summary.to_csv(updated_summary_file, index=False)\n","\n","# Display first few rows\n","print(speech_summary.head())\n","\n","print(f\"Updated dataset saved to: {updated_summary_file}\")\n"],"metadata":{"id":"GfIS70egNDhy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure \"Datum\" is in datetime format\n","speech_summary[\"Datum\"] = pd.to_datetime(speech_summary[\"Datum\"], errors=\"coerce\")\n","\n","# Check for duplicates in the \"Datum\" (date) column\n","duplicate_dates = speech_summary[\"Datum\"].duplicated().sum()\n","\n","# Check if all values in \"Datum\" are unique\n","if duplicate_dates == 0:\n","    print(\"All values in the 'Datum' column are unique.\")\n","else:\n","    print(f\"There are {duplicate_dates} duplicate entries in the 'Datum' column.\")"],"metadata":{"id":"9v7m8HBLciro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define file path\n","topics_file_path = \"/content/drive/My Drive/germanoptimized_speeches_with_topics_updated.csv\"\n","\n","# Load the dataset\n","topics_df = pd.read_csv(topics_file_path)\n","\n","# Display first few rows to confirm successful loading\n","print(\"Dataset successfully loaded. Preview:\")\n","print(topics_df.head())\n"],"metadata":{"id":"VWFnav08d3J-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_file_path = \"/content/drive/My Drive/German Pol Speeches/Speech_Level_Summary_With_Topics.csv\"\n","\n","\n","\n","# Merge speech_summary with topics_df based on \"speech_id\"\n","merged_df = speech_summary.merge(\n","    topics_df[[\"speech_id\", \"w_top_tot\", \"length\"]],\n","    on=\"speech_id\",\n","    how=\"left\"\n",")\n","\n","# Save the merged dataset back to Google Drive\n","merged_df.to_csv(merged_file_path, index=False)\n","\n"],"metadata":{"id":"UMTSjCvPeXtf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Rename the \"claim\" column to \"claimcount\"\n","merged_df = merged_df.rename(columns={\"claim\": \"claimcount\"})\n","merged_df = merged_df.rename(columns={\"Datum\": \"date\"})\n","\n","\n"],"metadata":{"id":"m_hluCheemrr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_df.to_csv(merged_file_path, index=False)"],"metadata":{"id":"yLY99haJfrQw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Define file paths\n","commission_path = \"/content/drive/My Drive/final_data_cleaned.csv\"\n","bundestag_path = \"/content/drive/My Drive/German Pol Speeches/Speech_Level_Summary_With_Topics.csv\"\n","\n","# Load the datasets\n","df_commission_raw = pd.read_csv(commission_path)\n","df_bundestag_raw = pd.read_csv(bundestag_path)\n","\n","# Display first rows to confirm successful loading\n","print(\"Commission Data:\")\n","display(df_commission_raw.head())\n","\n","print(\"\\nBundestag Data:\")\n","display(df_bundestag_raw.head())\n"],"metadata":{"id":"P417WZfSfyTb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Count occurrences of 1 (True) and 0 (False) in claimbinary\n","claimbinary_counts = df_bundestag_raw['claimbinary'].value_counts()\n","\n","# Display counts\n","print(\"Claimbinary Value Counts in Bundestag Data:\")\n","print(claimbinary_counts)\n","\n","# Specifically print the number of speeches with claims (1)\n","true_claims = claimbinary_counts.get(1, 0)  # Default to 0 if not found\n","print(f\"\\nNumber of speeches with claims (claimbinary = 1): {true_claims}\")\n"],"metadata":{"id":"scoLIgHrgFHE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check claimbinary counts for Bundestag\n","print(\"Bundestag Data - Claimbinary Counts:\")\n","print(df_bundestag_raw['claimbinary'].value_counts())\n","\n","# Check claimbinary counts for Commission\n","print(\"\\nCommission Data - Claimbinary Counts:\")\n","print(df_commission_raw['claimbinary'].value_counts())\n"],"metadata":{"id":"dg0Hyr5kgPTv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate claim probability for Bundestag\n","bundestag_claim_prob = df_bundestag_raw['claimbinary'].mean() * 100\n","\n","# Calculate claim probability for Commission\n","commission_claim_prob = df_commission_raw['claimbinary'].mean() * 100\n","\n","# Print results\n","print(f\"Bundestag - Claim Probability: {bundestag_claim_prob:.2f}%\")\n","print(f\"Commission - Claim Probability: {commission_claim_prob:.2f}%\")\n"],"metadata":{"id":"dbEunoYsgSPf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Data for the bar plot\n","systems = [\"Bundesregierung\", \"European Commission\"]\n","claim_probs = [bundestag_claim_prob, commission_claim_prob]\n","\n","# Define colors (Bundestag = Yellow, Commission = Blue)\n","colors = [\"#FFCC00\", \"#003399\"]\n","\n","# Create bar plot\n","plt.figure(figsize=(8,5))\n","plt.bar(systems, claim_probs, color=colors, edgecolor=\"black\")\n","\n","# Add value labels\n","for i, prob in enumerate(claim_probs):\n","    plt.text(i, prob + 0.5, f\"{prob:.2f}%\", ha=\"center\", fontsize=12, fontweight=\"bold\")\n","\n","# Formatting\n","plt.xlabel(\"System\")\n","plt.ylabel(\"Percentage of Speeches with Claims\")\n","plt.title(\"Claim-Making Probability in Bundesregierung vs. European Commission\")\n","plt.ylim(0, max(claim_probs) * 1.2)\n","plt.grid(axis=\"y\", linestyle=\"\", alpha=0)\n","\n","# Show plot\n","plt.show()\n"],"metadata":{"id":"OAUVdVl8gjxa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","\n","# Ensure date is in datetime format\n","df_bundestag_raw['date'] = pd.to_datetime(df_bundestag_raw['date'])\n","df_commission_raw['date'] = pd.to_datetime(df_commission_raw['date'])\n","\n","# Add system labels\n","df_bundestag_raw['system'] = 'Bundesregierung'\n","df_commission_raw['system'] = 'European Commission'\n","\n","# Select relevant columns and merge datasets\n","df_bundestag = df_bundestag_raw[['date', 'claimbinary', 'system']]\n","df_commission = df_commission_raw[['date', 'claimbinary', 'system']]\n","df_combined = pd.concat([df_bundestag, df_commission], ignore_index=True)\n","\n","# Extract year and create 5-year bins\n","df_combined['year'] = df_combined['date'].dt.year\n","df_combined['year_bin'] = (df_combined['year'] // 5) * 5  # Groups years into 5-year bins\n","\n","# Compute mean claim probability per 5-year period\n","df_time = df_combined.groupby(['year_bin', 'system'])['claimbinary'].mean().reset_index()\n","\n","# Plot\n","plt.figure(figsize=(10,6))\n","sns.lineplot(x='year_bin', y='claimbinary', hue='system', data=df_time, marker=\"o\", palette=[\"#FFCC00\", \"#003399\"])\n","\n","# Formatting\n","plt.xlabel(\"Year (5-Year Intervals)\")\n","plt.ylabel(\"Average Claim Probability\")\n","plt.title(\"Claim-Making Probability Over Time (5-Year Steps)\")\n","plt.ylim(0, df_time['claimbinary'].max() * 1.2)  # Scale y-axis for visibility\n","plt.xticks(rotation=45)\n","plt.grid(axis='y', linestyle=\"\", alpha=0)\n","plt.legend(title=\"System\")\n","\n","# Show plot\n","plt.show()\n"],"metadata":{"id":"KihtiFDthGm3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Ensure topic_share_women is numeric\n","df_bundestag_raw['w_top_tot'] = pd.to_numeric(df_bundestag_raw['w_top_tot'], errors='coerce')\n","df_commission_raw['w_top_tot'] = pd.to_numeric(df_commission_raw['w_top_tot'], errors='coerce')\n","\n","# Add system labels\n","df_bundestag_raw['system'] = 'Bundestag'\n","df_commission_raw['system'] = 'Commission'\n","\n","# Select relevant columns and merge datasets\n","df_bundestag = df_bundestag_raw[['w_top_tot', 'claimbinary', 'system']].dropna()\n","df_commission = df_commission_raw[['w_top_tot', 'claimbinary', 'system']].dropna()\n","df_combined = pd.concat([df_bundestag, df_commission], ignore_index=True)\n","\n","# Plot: Relationship between Topic Share Women and Claim Probability\n","plt.figure(figsize=(10,6))\n","sns.regplot(\n","    x='w_top_tot', y='claimbinary', data=df_combined,\n","    scatter_kws={'alpha':0.3}, line_kws={'color':'black'}, lowess=True\n",")\n","\n","# Formatting\n","plt.xlabel(\"Proportion of Speech on Women's Topics\")\n","plt.ylabel(\"Claim Probability (Binary Outcome)\")\n","plt.title(\"Effect of Women's Topic Share on Claim-Making\")\n","plt.grid(axis='y', linestyle=\"--\", alpha=0.7)\n","\n","# Show plot\n","plt.show()\n"],"metadata":{"id":"GZqSYKBrhoOq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Ensure dates are in datetime format\n","df_commission_raw['date'] = pd.to_datetime(df_commission_raw['date'])\n","df_bundestag_raw['date'] = pd.to_datetime(df_bundestag_raw['date'])\n","\n","# Rename key variables\n","rename_dict = {\n","    'European.Party_speakerinfo': 'party',\n","    'Sex_speakerinfo': 'sex'\n","}\n","df_commission_raw = df_commission_raw.rename(columns=rename_dict)\n","df_bundestag_raw = df_bundestag_raw.rename(columns=rename_dict)\n","\n","# Define event dates\n","event_commission = pd.Timestamp(\"2019-12-01\")\n","event_bundestag = pd.Timestamp(\"2005-11-01\")\n","\n","# Create running variable: days before/after the event\n","df_commission_raw['time_to_event'] = (df_commission_raw['date'] - event_commission).dt.days\n","df_bundestag_raw['time_to_event'] = (df_bundestag_raw['date'] - event_bundestag).dt.days\n","\n","# Select relevant columns\n","columns_to_keep = ['time_to_event', 'claimbinary', 'w_top_tot', 'length', 'party', 'sex']\n","df_commission = df_commission_raw[columns_to_keep].dropna()\n","df_bundestag = df_bundestag_raw[columns_to_keep].dropna()\n","\n","# Add system identifier\n","df_commission['system'] = \"Commission\"\n","df_bundestag['system'] = \"Bundestag\"\n","\n","# Combine datasets\n","df_combined = pd.concat([df_commission, df_bundestag], ignore_index=True)\n","\n","# Show data structure\n","print(df_combined.head())\n"],"metadata":{"id":"B3UmXy2ij7qA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check for missing values\n","print(\"Missing values per column:\\n\")\n","print(df_combined.isnull().sum())\n","\n","# Check unique values for categorical variables\n","print(\"\\nUnique values for 'sex':\", df_combined['sex'].unique())\n","print(\"Unique values for 'party':\", df_combined['party'].unique())\n"],"metadata":{"id":"3ayPdhrskKQ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Available columns in df_combined:\")\n","print(df_combined.columns)\n"],"metadata":{"id":"SgEiyj9RkQvH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Available columns in df_commission_raw:\")\n","print(df_commission_raw.columns)\n","\n","print(\"\\nAvailable columns in df_bundestag_raw:\")\n","print(df_bundestag_raw.columns)\n"],"metadata":{"id":"JBmeakaekUjC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Correct renaming, if needed\n","rename_dict = {\n","    'European.Party_speakerinfo': 'party',\n","    'Sex_speakerinfo': 'sex',  # Check if this matches your data!\n","    'sex_speakerinfo': 'sex'   # Alternative, in case the name is different\n","}\n","\n","df_commission_raw = df_commission_raw.rename(columns=rename_dict)\n","df_bundestag_raw = df_bundestag_raw.rename(columns=rename_dict)\n","\n","# Now check again:\n","print(\"\\nColumns after renaming:\")\n","print(df_commission_raw.columns)\n","print(df_bundestag_raw.columns)\n"],"metadata":{"id":"6_NWqHfmkYl3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Rename 'European Party_speakerinfo' to 'party' in Commission dataset\n","rename_dict = {\n","    'European Party_speakerinfo': 'party',  # Fix party name\n","    'Sex_speakerinfo': 'sex'  # Already fixed in previous step\n","}\n","\n","df_commission_raw = df_commission_raw.rename(columns=rename_dict)\n","\n","# Check if party and sex are now correctly named\n","print(\"\\nColumns after renaming in Commission dataset:\")\n","print(df_commission_raw.columns)\n","\n","print(\"\\nColumns after renaming in Bundestag dataset:\")\n","print(df_bundestag_raw.columns)\n"],"metadata":{"id":"AWvKkr26kbEb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["columns_to_keep = ['time_to_event', 'claimbinary', 'w_top_tot', 'length', 'party', 'sex']\n","\n","df_commission = df_commission_raw[columns_to_keep].dropna()\n","df_bundestag = df_bundestag_raw[columns_to_keep].dropna()\n","\n","df_commission['system'] = \"Commission\"\n","df_bundestag['system'] = \"Bundestag\"\n","\n","# Merge datasets\n","df_combined = pd.concat([df_commission, df_bundestag], ignore_index=True)\n","\n","# Final check: Do party and sex exist?\n","print(\"\\nFinal columns in df_combined:\")\n","print(df_combined.columns)\n"],"metadata":{"id":"nyD6C8JZktTD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check missing values\n","print(\"Missing values per column in df_combined:\")\n","print(df_combined.isnull().sum())\n","\n","# Check unique values for categorical variables\n","print(\"\\nUnique values for 'sex':\", df_combined['sex'].unique())\n","print(\"Unique values for 'party':\", df_combined['party'].unique())\n"],"metadata":{"id":"z4-afdEckxlY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a mapping dictionary for party names\n","party_mapping = {\n","    'PES': 'PES',\n","    'PES[34]': 'PES',\n","    'PES\\xa0/': 'PES',  # Handles special character issues\n","    'ALDE': 'ALDE',\n","    'ALDE[23]': 'ALDE',\n","    'ALDE[25]': 'ALDE',\n","    'ALDE[5]': 'ALDE',\n","    'ALDE[32]': 'ALDE',\n","    'ALDE[38]': 'ALDE',\n","    'EPP': 'EPP',\n","    'csu': 'EPP',  # Map CSU to EPP\n","    'EGP': 'EGP',\n","    'ECR': 'ECR',\n","    'ECR[41]': 'ECR'\n","}\n","\n","# Apply mapping to both datasets\n","df_commission_raw['party'] = df_commission_raw['party'].replace(party_mapping)\n","df_bundestag_raw['party'] = df_bundestag_raw['party'].replace(party_mapping)\n","\n","# Check if the replacements worked\n","print(\"Unique values for 'party' after cleaning:\")\n","print(df_commission_raw['party'].unique())\n","print(df_bundestag_raw['party'].unique())\n"],"metadata":{"id":"7xdhh4rtlIZU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\nUnexpected party values (Commission):\", df_commission_raw[~df_commission_raw['party'].isin(party_mapping.values())]['party'].unique())\n","print(\"Unexpected party values (Bundestag):\", df_bundestag_raw[~df_bundestag_raw['party'].isin(party_mapping.values())]['party'].unique())\n"],"metadata":{"id":"tuEtf36YlNHD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove rows where 'party' is NaN\n","df_bundestag_raw = df_bundestag_raw.dropna(subset=['party'])\n","\n","print(\"\\nRemaining missing values for 'party' in Bundestag dataset:\", df_bundestag_raw['party'].isna().sum())\n"],"metadata":{"id":"SRPJEQnpldBD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\nFinal unique values for 'party':\")\n","print(df_bundestag_raw['party'].unique())\n","print(df_commission_raw['party'].unique())\n"],"metadata":{"id":"9fjRMpvzlgGN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Select relevant columns\n","columns_to_keep = ['time_to_event', 'claimbinary', 'w_top_tot', 'length', 'party', 'sex']\n","df_commission = df_commission_raw[columns_to_keep].dropna()\n","df_bundestag = df_bundestag_raw[columns_to_keep].dropna()\n","\n","df_commission['system'] = \"Commission\"\n","df_bundestag['system'] = \"Bundestag\"\n","\n","# Merge datasets\n","df_combined = pd.concat([df_commission, df_bundestag], ignore_index=True)\n","\n","# Check final structure\n","print(\"\\nFinal columns in df_combined:\")\n","print(df_combined.columns)"],"metadata":{"id":"pWiccnfvlxv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","\n","# Define bandwidth (e.g., Â±4 years = 1460 days)\n","bandwidth = 1460\n","\n","# Filter data for the RDD window\n","df_rdd = df_combined[np.abs(df_combined['time_to_event']) <= bandwidth]\n","\n","# Split by gender\n","df_men = df_rdd[df_rdd['sex'] == 'male']\n","df_women = df_rdd[df_rdd['sex'] == 'female']\n","\n","# Logistic Regression Model (RDD)\n","formula = \"claimbinary ~ time_to_event + w_top_tot + length + party\"\n","\n","# Run RDD models\n","model_men = smf.logit(formula, data=df_men).fit()\n","model_women = smf.logit(formula, data=df_women).fit()\n","\n","# Display results\n","print(\"RDD Logistic Regression Results for Men:\")\n","print(model_men.summary())\n","\n","print(\"\\nRDD Logistic Regression Results for Women:\")\n","print(model_women.summary())\n"],"metadata":{"id":"ZsgEqS1sl0Rk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check data size after filtering\n","print(f\"Total rows in df_rdd: {df_rdd.shape[0]}\")\n","print(f\"Rows for men: {df_men.shape[0]}\")\n","print(f\"Rows for women: {df_women.shape[0]}\")\n","\n","# Check unique values in 'sex'\n","print(\"\\nUnique values in 'sex' column:\")\n","print(df_rdd['sex'].unique())\n"],"metadata":{"id":"aGpHpnuKmOQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert sex to categorical labels\n","df_rdd['sex'] = df_rdd['sex'].replace({0: 'male', 1: 'female'})\n","\n","# Re-filter after correction\n","df_men = df_rdd[df_rdd['sex'] == 'male']\n","df_women = df_rdd[df_rdd['sex'] == 'female']\n","\n","# Check unique values again\n","print(\"\\nFixed unique values in 'sex' column:\")\n","print(df_rdd['sex'].unique())\n","\n","print(f\"Rows for men after fix: {df_men.shape[0]}\")\n","print(f\"Rows for women after fix: {df_women.shape[0]}\")\n"],"metadata":{"id":"Gs90Ta_MmSi0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","\n","# Logistic Regression Model (RDD)\n","formula = \"claimbinary ~ time_to_event + w_top_tot + length + party\"\n","\n","# Run RDD models\n","if df_men.shape[0] > 0:\n","    model_men = smf.logit(formula, data=df_men).fit()\n","    print(\"RDD Logistic Regression Results for Men:\")\n","    print(model_men.summary())\n","else:\n","    print(\"Not enough data for men.\")\n","\n","if df_women.shape[0] > 0:\n","    model_women = smf.logit(formula, data=df_women).fit()\n","    print(\"\\nRDD Logistic Regression Results for Women:\")\n","    print(model_women.summary())\n","else:\n","    print(\"Not enough data for women.\")\n"],"metadata":{"id":"mEBdBm-_mVm8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Filter data for each system within Â±2 years\n","df_commission_rdd = df_rdd[df_rdd['system'] == \"Commission\"]\n","df_bundestag_rdd = df_rdd[df_rdd['system'] == \"Bundestag\"]\n","\n","# Split by gender\n","df_commission_men = df_commission_rdd[df_commission_rdd['sex'] == 'male']\n","df_commission_women = df_commission_rdd[df_commission_rdd['sex'] == 'female']\n","df_bundestag_men = df_bundestag_rdd[df_bundestag_rdd['sex'] == 'male']\n","df_bundestag_women = df_bundestag_rdd[df_bundestag_rdd['sex'] == 'female']\n","\n","# Define the logistic regression formula\n","formula = \"claimbinary ~ time_to_event + w_top_tot + length + party\"\n","\n","# Run separate models\n","print(\"\\nCommission - Men\")\n","model_commission_men = smf.logit(formula, data=df_commission_men).fit()\n","print(model_commission_men.summary())\n","\n","print(\"\\nCommission - Women\")\n","model_commission_women = smf.logit(formula, data=df_commission_women).fit()\n","print(model_commission_women.summary())\n","\n","print(\"\\nBundestag - Men\")\n","model_bundestag_men = smf.logit(formula, data=df_bundestag_men).fit()\n","print(model_bundestag_men.summary())\n","\n","print(\"\\nBundestag - Women\")\n","model_bundestag_women = smf.logit(formula, data=df_bundestag_women).fit()\n","print(model_bundestag_women.summary())\n"],"metadata":{"id":"9P33DKIYnBO6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add interaction term: system Ã— time_to_event\n","formula_interaction = \"claimbinary ~ time_to_event * system + w_top_tot + length + party\"\n","\n","# Run pooled model\n","model_interaction = smf.logit(formula_interaction, data=df_rdd).fit()\n","\n","# Print results\n","print(\"\\nInteraction Model: Does Institutional Setup Change Time Effects?\")\n","print(model_interaction.summary())\n"],"metadata":{"id":"0Gs6o-1mnGj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure datasets are loaded and merged\n","import pandas as pd\n","import numpy as np\n","\n","# Reload Commission and Bundestag datasets\n","df_combined = pd.concat([df_commission, df_bundestag], ignore_index=True)\n","\n","# Define the event time window (Â±2 years)\n","bandwidth = 10000\n","df_rdd = df_combined[np.abs(df_combined['time_to_event']) <= bandwidth]\n","\n","# Separate by institution\n","df_commission_rdd = df_rdd[df_rdd['system'] == \"Commission\"]\n","df_bundestag_rdd = df_rdd[df_rdd['system'] == \"Bundestag\"]\n","\n","# Check dataset sizes\n","print(f\"Commission RDD dataset: {df_commission_rdd.shape[0]} observations\")\n","print(f\"Bundestag RDD dataset: {df_bundestag_rdd.shape[0]} observations\")\n"],"metadata":{"id":"4ORX-JHVoIlY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","# Define bin width (100 days)\n","bin_width = 200\n","\n","# Function to create binned data\n","def bin_time_data(df, system_name, color):\n","    df['time_bin'] = np.floor(df['time_to_event'] / bin_width) * bin_width  # Group into 100-day bins\n","    bin_avg = df.groupby('time_bin')['claimbinary'].mean().reset_index()\n","\n","    plt.figure(figsize=(10,6))\n","    sns.scatterplot(x='time_bin', y='claimbinary', data=bin_avg, color=color, label=system_name)\n","    sns.lineplot(x='time_bin', y='claimbinary', data=bin_avg, color=color)\n","\n","    plt.axvline(0, color='red', linestyle=\"--\", label=\"Event Date\")\n","    plt.xlabel(\"Days from Event\")\n","    plt.ylabel(\"Average Claim Probability\")\n","    plt.title(f\"RDD Effect on Claim-Making ({system_name}) - Binned Data\")\n","    plt.legend()\n","    plt.grid(axis='y', linestyle=\"--\", alpha=0.7)\n","    plt.show()\n","\n","# Plot for Commission and Bundestag\n","bin_time_data(df_commission_rdd, \"European Commission\", \"#003399\")\n","bin_time_data(df_bundestag_rdd, \"German Bundestag\", \"#FFCC00\")\n"],"metadata":{"id":"z2mnAqpBoRNa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a before/after indicator\n","df_rdd['before_event'] = df_rdd['time_to_event'] < 0\n","\n","# Compute mean claim probability before vs. after event\n","mean_claims = df_rdd.groupby(['before_event', 'system'])['claimbinary'].mean().reset_index()\n","\n","# Rename values for plotting\n","mean_claims['before_event'] = mean_claims['before_event'].replace({True: \"Before Event\", False: \"After Event\"})\n","\n","# Plot bar chart\n","plt.figure(figsize=(10,6))\n","sns.barplot(x='before_event', y='claimbinary', hue='system', data=mean_claims, palette={\"Commission\": \"#003399\", \"Bundestag\": \"#FFCC00\"})\n","\n","plt.xlabel(\"Event Period\")\n","plt.ylabel(\"Mean Claim Probability\")\n","plt.title(\"Comparison of Claim Probability Before and After the Event\")\n","plt.legend(title=\"Institution\")\n","plt.grid(axis='y', linestyle=\"--\", alpha=0.7)\n","plt.show()\n"],"metadata":{"id":"kMpASsRupDK-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","import seaborn as sns\n","\n","# Define range of days for predictions (Â±800 days)\n","time_range = np.linspace(-8000, 8000, 100)\n","\n","# Create a dataframe for prediction\n","df_pred = pd.DataFrame({'time_to_event': time_range})\n","df_pred['w_top_tot'] = df_rdd['w_top_tot'].mean()  # Use mean of w_top_tot\n","df_pred['length'] = df_rdd['length'].mean()  # Use mean of length\n","df_pred['party'] = \"EPP\"  # Choose a reference category for party\n","\n","# Predict probabilities for Commission\n","df_pred_commission = df_pred.copy()\n","df_pred_commission['system'] = \"Commission\"\n","df_pred_commission['system_Commission'] = 1  # Dummy for interaction\n","df_pred_commission['pred_prob'] = model_commission_men.predict(df_pred_commission)\n","\n","# Predict probabilities for Bundestag\n","df_pred_bundestag = df_pred.copy()\n","df_pred_bundestag['system'] = \"Bundestag\"\n","df_pred_bundestag['system_Commission'] = 0  # Dummy for interaction\n","df_pred_bundestag['pred_prob'] = model_bundestag_men.predict(df_pred_bundestag)\n","\n","# Combine both datasets for plotting\n","df_pred_combined = pd.concat([df_pred_commission, df_pred_bundestag])\n","\n","# Plot RDD with estimated probabilities\n","plt.figure(figsize=(10,6))\n","sns.lineplot(x='time_to_event', y='pred_prob', hue='system', data=df_pred_combined, palette={\"Commission\": \"#003399\", \"Bundestag\": \"#FFCC00\"})\n","\n","plt.axvline(0, color='red', linestyle=\"--\", label=\"Event Date\")\n","plt.xlabel(\"Days from Event\")\n","plt.ylabel(\"Predicted Claim Probability\")\n","plt.title(\"Regression Discontinuity: Estimated Claim-Making Probability\")\n","plt.legend(title=\"Institution\")\n","plt.grid(axis='y', linestyle=\"--\", alpha=0.7)\n","plt.show()\n"],"metadata":{"id":"_AVUzC9mptEg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Function to fit separate pre/post RDD models\n","def fit_rdd_models(df):\n","    df_pre = df[df['time_to_event'] < 0]\n","    df_post = df[df['time_to_event'] >= 0]\n","\n","    # Logistic regression models\n","    model_pre = smf.logit(\"claimbinary ~ time_to_event + w_top_tot + length + party\", data=df_pre).fit()\n","    model_post = smf.logit(\"claimbinary ~ time_to_event + w_top_tot + length + party\", data=df_post).fit()\n","\n","    return model_pre, model_post\n","\n","# Fit RDD models separately for Commission and Bundestag\n","model_commission_pre, model_commission_post = fit_rdd_models(df_commission_rdd)\n","model_bundestag_pre, model_bundestag_post = fit_rdd_models(df_bundestag_rdd)\n"],"metadata":{"id":"UuxyVC06p3zB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define range of days for predictions (Â±800 days)\n","time_range_pre = np.linspace(-800, -1, 50)\n","time_range_post = np.linspace(0, 800, 50)\n","\n","# Function to predict probabilities\n","def predict_rdd(model_pre, model_post, df, time_range_pre, time_range_post):\n","    df_pred_pre = pd.DataFrame({'time_to_event': time_range_pre})\n","    df_pred_pre['w_top_tot'] = df['w_top_tot'].mean()\n","    df_pred_pre['length'] = df['length'].mean()\n","    df_pred_pre['party'] = \"EPP\"  # Set reference party\n","\n","    df_pred_post = df_pred_pre.copy()\n","    df_pred_post['time_to_event'] = time_range_post\n","\n","    # Get predicted probabilities\n","    df_pred_pre['pred_prob'] = model_pre.predict(df_pred_pre)\n","    df_pred_post['pred_prob'] = model_post.predict(df_pred_post)\n","\n","    return df_pred_pre, df_pred_post\n","\n","# Predict separately for Commission & Bundestag\n","df_commission_pred_pre, df_commission_pred_post = predict_rdd(model_commission_pre, model_commission_post, df_commission_rdd, time_range_pre, time_range_post)\n","df_bundestag_pred_pre, df_bundestag_pred_post = predict_rdd(model_bundestag_pre, model_bundestag_post, df_bundestag_rdd, time_range_pre, time_range_post)\n"],"metadata":{"id":"a8vjLv0OqPit"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to plot true RDD effect\n","def plot_rdd_discontinuity(df_pred_pre, df_pred_post, system_name, color):\n","    plt.figure(figsize=(10,6))\n","\n","    # Plot predictions\n","    sns.lineplot(x='time_to_event', y='pred_prob', data=df_pred_pre, color=color, label=f\"{system_name} (Before Event)\")\n","    sns.lineplot(x='time_to_event', y='pred_prob', data=df_pred_post, color=color, linestyle=\"dashed\", label=f\"{system_name} (After Event)\")\n","\n","    # Add event line\n","    plt.axvline(0, color='red', linestyle=\"--\", label=\"Event Date\")\n","    plt.xlabel(\"Days from Event\")\n","    plt.ylabel(\"Predicted Claim Probability\")\n","    plt.title(f\"RDD Effect on Claim-Making ({system_name}) - True Discontinuity\")\n","    plt.legend()\n","    plt.grid(axis='y', linestyle=\"--\", alpha=0.7)\n","    plt.show()\n","\n","# Plot true RDD for Commission & Bundestag\n","plot_rdd_discontinuity(df_commission_pred_pre, df_commission_pred_post, \"European Commission\", \"#003399\")\n","plot_rdd_discontinuity(df_bundestag_pred_pre, df_bundestag_pred_post, \"German Bundestag\", \"#FFCC00\")\n"],"metadata":{"id":"r9DTBh8UqWPT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,6))\n","\n","# Plot predictions\n","sns.lineplot(x='time_to_event', y='pred_prob', data=df_commission_pred_pre, color=\"#003399\", label=\"Commission (Before Event)\")\n","sns.lineplot(x='time_to_event', y='pred_prob', data=df_commission_pred_post, color=\"#003399\", linestyle=\"dashed\", label=\"Commission (After Event)\")\n","\n","sns.lineplot(x='time_to_event', y='pred_prob', data=df_bundestag_pred_pre, color=\"#FFCC00\", label=\"Bundesregierung (Before Event)\")\n","sns.lineplot(x='time_to_event', y='pred_prob', data=df_bundestag_pred_post, color=\"#FFCC00\", linestyle=\"dashed\", label=\"Bundesregierung (After Event)\")\n","\n","# Add event line\n","plt.axvline(0, color='red', linestyle=\"--\", label=\"Event Date\")\n","plt.xlabel(\"Days from Event\")\n","plt.ylabel(\"Predicted Claim Probability\")\n","plt.title(\"Woman Leader Effect on Claim-Making: Institutional Comparison\")\n","plt.legend()\n","plt.grid(axis='y', linestyle=\"\", alpha=0)\n","\n","plt.show()\n"],"metadata":{"id":"uQd8ydzBqjhS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a shorter range for better visibility\n","time_range_pre = np.linspace(-1000, -1, 50)\n","time_range_post = np.linspace(0, 1000, 50)\n","\n","# Predict for the new restricted time range\n","df_commission_pred_pre, df_commission_pred_post = predict_rdd(model_commission_pre, model_commission_post, df_commission_rdd, time_range_pre, time_range_post)\n","df_bundestag_pred_pre, df_bundestag_pred_post = predict_rdd(model_bundestag_pre, model_bundestag_post, df_bundestag_rdd, time_range_pre, time_range_post)\n","\n","# Plot with new range\n","plt.figure(figsize=(10,6))\n","\n","# Plot predictions\n","sns.lineplot(x='time_to_event', y='pred_prob', data=df_commission_pred_pre, color=\"#003399\", label=\"European Commission (Before Event)\")\n","sns.lineplot(x='time_to_event', y='pred_prob', data=df_commission_pred_post, color=\"#003399\", linestyle=\"dashed\", label=\"European Commission (After Event)\")\n","\n","sns.lineplot(x='time_to_event', y='pred_prob', data=df_bundestag_pred_pre, color=\"#FFCC00\", label=\"Bundesregierung (Before Event)\")\n","sns.lineplot(x='time_to_event', y='pred_prob', data=df_bundestag_pred_post, color=\"#FFCC00\", linestyle=\"dashed\", label=\"Bundesregierung (After Event)\")\n","\n","# Add event line\n","plt.axvline(0, color='red', linestyle=\"--\", label=\"Event Date\")\n","plt.xlabel(\"Days from Event\")\n","plt.ylabel(\"Predicted Claim Probability\")\n","plt.title(\"RDD Effect on Claim-Making: Institutional Comparison (Â±1000 days)\")\n","plt.legend()\n","plt.grid(axis='y', linestyle=\"\", alpha=0)\n","\n","plt.show()\n"],"metadata":{"id":"nESMTM5PrSWU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to calculate confidence intervals for RDD\n","def predict_with_ci(model, df, time_range):\n","    df_pred = pd.DataFrame({'time_to_event': time_range})\n","    df_pred['w_top_tot'] = df['w_top_tot'].mean()\n","    df_pred['length'] = df['length'].mean()\n","    df_pred['party'] = \"EPP\"  # Reference party\n","\n","    # Predict probabilities\n","    df_pred['pred_prob'] = model.predict(df_pred)\n","\n","    # Compute confidence intervals\n","    pred_std = model.bse[0]  # Standard error\n","    df_pred['lower_ci'] = df_pred['pred_prob'] - 1.96 * pred_std\n","    df_pred['upper_ci'] = df_pred['pred_prob'] + 1.96 * pred_std\n","\n","    return df_pred\n","\n","# Predict with confidence intervals\n","df_commission_pre_ci = predict_with_ci(model_commission_pre, df_commission_rdd, time_range_pre)\n","df_commission_post_ci = predict_with_ci(model_commission_post, df_commission_rdd, time_range_post)\n","df_bundestag_pre_ci = predict_with_ci(model_bundestag_pre, df_bundestag_rdd, time_range_pre)\n","df_bundestag_post_ci = predict_with_ci(model_bundestag_post, df_bundestag_rdd, time_range_post)\n","\n","# Plot with confidence intervals\n","plt.figure(figsize=(10,6))\n","\n","# Commission\n","sns.lineplot(x='time_to_event', y='pred_prob', data=df_commission_pre_ci, color=\"#003399\", label=\"Commission (Before Event)\")\n","sns.lineplot(x='time_to_event', y='pred_prob', data=df_commission_post_ci, color=\"#003399\", linestyle=\"dashed\", label=\"Commission (After Event)\")\n","\n","plt.fill_between(df_commission_pre_ci['time_to_event'], df_commission_pre_ci['lower_ci'], df_commission_pre_ci['upper_ci'], color=\"#003399\", alpha=0.2)\n","plt.fill_between(df_commission_post_ci['time_to_event'], df_commission_post_ci['lower_ci'], df_commission_post_ci['upper_ci'], color=\"#003399\", alpha=0.2)\n","\n","# Bundestag\n","sns.lineplot(x='time_to_event', y='pred_prob', data=df_bundestag_pre_ci, color=\"#FFCC00\", label=\"Bundestag (Before Event)\")\n","sns.lineplot(x='time_to_event', y='pred_prob', data=df_bundestag_post_ci, color=\"#FFCC00\", linestyle=\"dashed\", label=\"Bundestag (After Event)\")\n","\n","plt.fill_between(df_bundestag_pre_ci['time_to_event'], df_bundestag_pre_ci['lower_ci'], df_bundestag_pre_ci['upper_ci'], color=\"#FFCC00\", alpha=0.2)\n","plt.fill_between(df_bundestag_post_ci['time_to_event'], df_bundestag_post_ci['lower_ci'], df_bundestag_post_ci['upper_ci'], color=\"#FFCC00\", alpha=0.2)\n","\n","# Add event line\n","plt.axvline(0, color='red', linestyle=\"--\", label=\"Event Date\")\n","plt.xlabel(\"Days from Event\")\n","plt.ylabel(\"Predicted Claim Probability\")\n","plt.title(\"RDD Effect on Claim-Making: Institutional Comparison (with Confidence Intervals)\")\n","plt.legend()\n","plt.grid(axis='y', linestyle=\"--\", alpha=0.7)\n","\n","plt.show()\n"],"metadata":{"id":"mJW19G5qrbhn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","\n","# Function to fit separate pre/post RDD models\n","def fit_rdd_models(df):\n","    df_pre = df[df['time_to_event'] < 0]\n","    df_post = df[df['time_to_event'] >= 0]\n","\n","    # Fit logistic regression models for pre and post event\n","    model_pre = smf.logit(\"claimbinary ~ time_to_event + w_top_tot + length + party\", data=df_pre).fit()\n","    model_post = smf.logit(\"claimbinary ~ time_to_event + w_top_tot + length + party\", data=df_post).fit()\n","\n","    return model_pre, model_post\n"],"metadata":{"id":"jjTXbgxrtEPo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fit models separately by gender and institution\n","model_commission_men_pre, model_commission_men_post = fit_rdd_models(df_commission_rdd[df_commission_rdd['sex'] == 'male'])\n","model_commission_women_pre, model_commission_women_post = fit_rdd_models(df_commission_rdd[df_commission_rdd['sex'] == 'female'])\n","\n","model_bundestag_men_pre, model_bundestag_men_post = fit_rdd_models(df_bundestag_rdd[df_bundestag_rdd['sex'] == 'male'])\n","model_bundestag_women_pre, model_bundestag_women_post = fit_rdd_models(df_bundestag_rdd[df_bundestag_rdd['sex'] == 'female'])\n"],"metadata":{"id":"ZAh8kp_HtGto"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert numerical encoding to labels (if necessary)\n","df_commission_rdd['sex'] = df_commission_rdd['sex'].replace({0: 'male', 1: 'female'})\n","df_bundestag_rdd['sex'] = df_bundestag_rdd['sex'].replace({0: 'male', 1: 'female'})\n","\n","# Verify the correction\n","print(\"Unique values after correction:\", df_commission_rdd['sex'].unique())\n"],"metadata":{"id":"_Z5MKhxotT_E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check dataset sizes before running RDD models\n","df_commission_men = df_commission_rdd[df_commission_rdd['sex'] == 'male']\n","df_commission_women = df_commission_rdd[df_commission_rdd['sex'] == 'female']\n","\n","df_bundestag_men = df_bundestag_rdd[df_bundestag_rdd['sex'] == 'male']\n","df_bundestag_women = df_bundestag_rdd[df_bundestag_rdd['sex'] == 'female']\n","\n","print(\"\\nNumber of observations by gender in Commission dataset:\")\n","print(f\"Men: {df_commission_men.shape[0]}, Women: {df_commission_women.shape[0]}\")\n","\n","print(\"\\nNumber of observations by gender in Bundestag dataset:\")\n","print(f\"Men: {df_bundestag_men.shape[0]}, Women: {df_bundestag_women.shape[0]}\")\n"],"metadata":{"id":"8uu0vR87tZQB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fit models only if data exists\n","models = {}\n","\n","for label, df in [(\"commission_men\", df_commission_men), (\"commission_women\", df_commission_women),\n","                  (\"bundestag_men\", df_bundestag_men), (\"bundestag_women\", df_bundestag_women)]:\n","    if df.shape[0] > 10:  # Ensure enough data points\n","        print(f\"Fitting RDD model for {label}...\")\n","        models[f\"{label}_pre\"], models[f\"{label}_post\"] = fit_rdd_models(df)\n","    else:\n","        print(f\"Skipping RDD model for {label} (not enough data).\")\n"],"metadata":{"id":"cQfeAW53teD7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","\n","# Function to fit separate pre/post RDD models\n","def fit_rdd_models(df):\n","    df_pre = df[df['time_to_event'] < 0]\n","    df_post = df[df['time_to_event'] >= 0]\n","\n","    # Fit logistic regression models for pre and post event\n","    model_pre = smf.logit(\"claimbinary ~ time_to_event + w_top_tot + length + party\", data=df_pre).fit()\n","    model_post = smf.logit(\"claimbinary ~ time_to_event + w_top_tot + length + party\", data=df_post).fit()\n","\n","    return model_pre, model_post\n"],"metadata":{"id":"b0YpqjiitkG6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fit models separately by gender and institution\n","model_commission_men_pre, model_commission_men_post = fit_rdd_models(df_commission_rdd[df_commission_rdd['sex'] == 'male'])\n","model_commission_women_pre, model_commission_women_post = fit_rdd_models(df_commission_rdd[df_commission_rdd['sex'] == 'female'])\n","\n","model_bundestag_men_pre, model_bundestag_men_post = fit_rdd_models(df_bundestag_rdd[df_bundestag_rdd['sex'] == 'male'])\n","model_bundestag_women_pre, model_bundestag_women_post = fit_rdd_models(df_bundestag_rdd[df_bundestag_rdd['sex'] == 'female'])\n"],"metadata":{"id":"vuF4aIOJtmXi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.special import expit  # Sigmoid function\n","\n","# Function to predict probabilities with correct transformation\n","def predict_with_fixed_ci(model, df, time_range):\n","    df_pred = pd.DataFrame({'time_to_event': time_range})\n","    df_pred['w_top_tot'] = df['w_top_tot'].mean()\n","    df_pred['length'] = df['length'].mean()\n","    df_pred['party'] = \"EPP\"  # Reference party\n","\n","    # Predict log-odds\n","    df_pred['logit'] = model.predict(df_pred)\n","\n","    # Convert log-odds to probability using sigmoid\n","    df_pred['pred_prob'] = expit(df_pred['logit'])\n","\n","    # Compute confidence intervals\n","    pred_std = model.bse[0]  # Standard error\n","    df_pred['lower_ci'] = expit(df_pred['logit'] - 1.96 * pred_std)\n","    df_pred['upper_ci'] = expit(df_pred['logit'] + 1.96 * pred_std)\n","\n","    return df_pred\n","\n","# Define prediction time range\n","time_range_pre = np.linspace(-1000, -1, 50)\n","time_range_post = np.linspace(0, 1000, 50)\n","\n","# Compute predictions separately for men and women\n","df_commission_men_pre, df_commission_men_post = predict_with_fixed_ci(model_commission_men_pre, df_commission_rdd, time_range_pre), predict_with_fixed_ci(model_commission_men_post, df_commission_rdd, time_range_post)\n","df_commission_women_pre, df_commission_women_post = predict_with_fixed_ci(model_commission_women_pre, df_commission_rdd, time_range_pre), predict_with_fixed_ci(model_commission_women_post, df_commission_rdd, time_range_post)\n","\n","df_bundestag_men_pre, df_bundestag_men_post = predict_with_fixed_ci(model_bundestag_men_pre, df_bundestag_rdd, time_range_pre), predict_with_fixed_ci(model_bundestag_men_post, df_bundestag_rdd, time_range_post)\n","df_bundestag_women_pre, df_bundestag_women_post = predict_with_fixed_ci(model_bundestag_women_pre, df_bundestag_rdd, time_range_pre), predict_with_fixed_ci(model_bundestag_women_post, df_bundestag_rdd, time_range_post)\n"],"metadata":{"id":"kpOtrvppto6h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Function to plot RDD for men and women separately\n","def plot_rdd_by_sex(df_men_pre, df_men_post, df_women_pre, df_women_post, system_name, color_men, color_women):\n","    plt.figure(figsize=(10,6))\n","\n","    # Men\n","    sns.lineplot(x='time_to_event', y='pred_prob', data=df_men_pre, color=color_men, label=f\"{system_name} - Men (Before Event)\")\n","    sns.lineplot(x='time_to_event', y='pred_prob', data=df_men_post, color=color_men, linestyle=\"dashed\", label=f\"{system_name} - Men (After Event)\")\n","\n","    plt.fill_between(df_men_pre['time_to_event'], df_men_pre['lower_ci'], df_men_pre['upper_ci'], color=color_men, alpha=0.2)\n","    plt.fill_between(df_men_post['time_to_event'], df_men_post['lower_ci'], df_men_post['upper_ci'], color=color_men, alpha=0.2)\n","\n","    # Women\n","    sns.lineplot(x='time_to_event', y='pred_prob', data=df_women_pre, color=color_women, label=f\"{system_name} - Women (Before Event)\")\n","    sns.lineplot(x='time_to_event', y='pred_prob', data=df_women_post, color=color_women, linestyle=\"dashed\", label=f\"{system_name} - Women (After Event)\")\n","\n","    plt.fill_between(df_women_pre['time_to_event'], df_women_pre['lower_ci'], df_women_pre['upper_ci'], color=color_women, alpha=0.2)\n","    plt.fill_between(df_women_post['time_to_event'], df_women_post['lower_ci'], df_women_post['upper_ci'], color=color_women, alpha=0.2)\n","\n","    # Event line\n","    plt.axvline(0, color='red', linestyle=\"--\", label=\"Event Date\")\n","    plt.xlabel(\"Days from Event\")\n","    plt.ylabel(\"Predicted Claim Probability\")\n","    plt.title(f\"RDD Effect on Claim-Making: {system_name} (Men vs. Women)\")\n","    plt.legend()\n","    plt.grid(axis='y', linestyle=\"--\", alpha=0.7)\n","\n","    plt.show()\n","\n","# Plot for Commission and Bundestag\n","plot_rdd_by_sex(df_commission_men_pre, df_commission_men_post, df_commission_women_pre, df_commission_women_post, \"European Commission\", \"#003399\", \"#6699FF\")\n","plot_rdd_by_sex(df_bundestag_men_pre, df_bundestag_men_post, df_bundestag_women_pre, df_bundestag_women_post, \"German Bundestag\", \"#FFCC00\", \"#FFD700\")\n"],"metadata":{"id":"Y58pC9MptrqS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to get predicted probabilities with correct confidence intervals\n","def predict_with_fixed_ci(model, df, time_range):\n","    df_pred = pd.DataFrame({'time_to_event': time_range})\n","    df_pred['w_top_tot'] = df['w_top_tot'].mean()\n","    df_pred['length'] = df['length'].mean()\n","    df_pred['party'] = \"EPP\"  # Reference party\n","\n","    # Get predictions with confidence intervals\n","    pred_results = model.get_prediction(df_pred)\n","    pred_summary = pred_results.summary_frame(alpha=0.05)  # 95% CI\n","\n","    # Convert log-odds to probabilities\n","    df_pred['pred_prob'] = expit(pred_summary['mean'])\n","    df_pred['lower_ci'] = expit(pred_summary['mean_ci_lower'])\n","    df_pred['upper_ci'] = expit(pred_summary['mean_ci_upper'])\n","\n","    return df_pred\n","\n","# Recompute predictions with corrected CIs\n","df_commission_men_pre, df_commission_men_post = predict_with_fixed_ci(model_commission_men_pre, df_commission_rdd, time_range_pre), predict_with_fixed_ci(model_commission_men_post, df_commission_rdd, time_range_post)\n","df_commission_women_pre, df_commission_women_post = predict_with_fixed_ci(model_commission_women_pre, df_commission_rdd, time_range_pre), predict_with_fixed_ci(model_commission_women_post, df_commission_rdd, time_range_post)\n"],"metadata":{"id":"7sKn7DJUuSUl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to get predicted probabilities with correct confidence intervals\n","def predict_with_fixed_ci(model, df, time_range):\n","    df_pred = pd.DataFrame({'time_to_event': time_range})\n","    df_pred['w_top_tot'] = df['w_top_tot'].mean()\n","    df_pred['length'] = df['length'].mean()\n","    df_pred['party'] = \"EPP\"  # Reference party\n","\n","    # Get predictions with confidence intervals\n","    pred_results = model.get_prediction(df_pred)\n","    pred_summary = pred_results.summary_frame(alpha=0.05)  # 95% CI\n","\n","    # Convert log-odds to probabilities\n","    df_pred['pred_prob'] = expit(pred_summary['mean'])\n","    df_pred['lower_ci'] = expit(pred_summary['mean_ci_lower'])\n","    df_pred['upper_ci'] = expit(pred_summary['mean_ci_upper'])\n","\n","    return df_pred\n","\n","# Recompute predictions with corrected CIs\n","df_commission_men_pre, df_commission_men_post = predict_with_fixed_ci(model_commission_men_pre, df_commission_rdd, time_range_pre), predict_with_fixed_ci(model_commission_men_post, df_commission_rdd, time_range_post)\n","df_commission_women_pre, df_commission_women_post = predict_with_fixed_ci(model_commission_women_pre, df_commission_rdd, time_range_pre), predict_with_fixed_ci(model_commission_women_post, df_commission_rdd, time_range_post)\n"],"metadata":{"id":"0LsnslTSucwW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to predict probabilities with correct confidence intervals\n","def predict_with_fixed_ci(model, df, time_range):\n","    df_pred = pd.DataFrame({'time_to_event': time_range})\n","    df_pred['w_top_tot'] = df['w_top_tot'].mean()\n","    df_pred['length'] = df['length'].mean()\n","    df_pred['party'] = \"EPP\"  # Reference party\n","\n","    # Get predicted values\n","    pred_results = model.get_prediction(df_pred)\n","\n","    # Extract predicted probabilities\n","    df_pred['pred_prob'] = expit(pred_results.predicted_mean)\n","\n","    # Compute confidence intervals\n","    ci = pred_results.conf_int(alpha=0.05)  # 95% confidence interval\n","    df_pred['lower_ci'] = expit(ci[:, 0])  # Convert log-odds to probability\n","    df_pred['upper_ci'] = expit(ci[:, 1])  # Convert log-odds to probability\n","\n","    return df_pred\n"],"metadata":{"id":"5qZJFJT0usWF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure the main RDD dataset exists\n","df_rdd = pd.concat([df_commission_rdd, df_bundestag_rdd], ignore_index=True)\n","\n","# Split datasets by sex and system\n","df_commission_men = df_commission_rdd[df_commission_rdd['sex'] == 'male']\n","df_commission_women = df_commission_rdd[df_commission_rdd['sex'] == 'female']\n","\n","df_bundestag_men = df_bundestag_rdd[df_bundestag_rdd['sex'] == 'male']\n","df_bundestag_women = df_bundestag_rdd[df_bundestag_rdd['sex'] == 'female']\n","\n","# Print the number of observations\n","print(\"\\nNumber of observations by gender and institution:\")\n","print(f\"Commission - Men: {df_commission_men.shape[0]}, Women: {df_commission_women.shape[0]}\")\n","print(f\"Bundestag - Men: {df_bundestag_men.shape[0]}, Women: {df_bundestag_women.shape[0]}\")\n"],"metadata":{"id":"fNx__tsLvCev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to test statistical significance of RDD discontinuity\n","import statsmodels.formula.api as smf\n","\n","def test_rdd_significance(df, system_name, sex_category):\n","    \"\"\"\n","    Runs a logistic regression model including a discontinuity term and prints the statistical significance.\n","    The model includes an interaction term between `time_to_event` and a binary indicator for post-event period.\n","    \"\"\"\n","    df = df.copy()\n","\n","    # Create binary variable for post-event period\n","    df['post_event'] = (df['time_to_event'] >= 0).astype(int)\n","\n","    # Fit the logistic regression model with discontinuity\n","    model = smf.logit(\"claimbinary ~ time_to_event + post_event + time_to_event:post_event + w_top_tot + length + party\", data=df).fit()\n","\n","    # Print model results\n","    print(f\"\\nRDD Discontinuity Test - {system_name} ({sex_category}):\")\n","    print(model.summary())\n","\n","    return model\n","\n","# Test discontinuity separately for men and women in each institution\n","model_rdd_commission_men = test_rdd_significance(df_commission_men, \"European Commission\", \"Men\")\n","model_rdd_commission_women = test_rdd_significance(df_commission_women, \"European Commission\", \"Women\")\n","model_rdd_bundestag_men = test_rdd_significance(df_bundestag_men, \"German Bundestag\", \"Men\")\n","model_rdd_bundestag_women = test_rdd_significance(df_bundestag_women, \"German Bundestag\", \"Women\")\n"],"metadata":{"id":"c2ntV_drvIh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define party mapping\n","party_mapping = {\n","    'PES': 'left',\n","    'EGP': 'left',\n","    'EPP': 'cons',\n","    'ALDE': 'cons'\n","}\n","\n","# Apply mapping\n","df_commission_rdd['party_group'] = df_commission_rdd['party'].map(party_mapping).fillna('other')\n","df_bundestag_rdd['party_group'] = df_bundestag_rdd['party'].map(party_mapping).fillna('other')\n","\n","# Check new value distribution\n","print(\"\\nNew Party Group Distribution (Commission):\\n\", df_commission_rdd['party_group'].value_counts())\n","print(\"\\nNew Party Group Distribution (Bundestag):\\n\", df_bundestag_rdd['party_group'].value_counts())\n"],"metadata":{"id":"-v4WYoCawRUx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import statsmodels.formula.api as smf\n","\n","def test_rdd_significance_with_party(df, system_name, sex_category):\n","    df = df.copy()\n","    df['post_event'] = (df['time_to_event'] >= 0).astype(int)\n","\n","    # Fit logistic regression model using 'party_group'\n","    model = smf.logit(\"claimbinary ~ time_to_event + post_event + time_to_event:post_event + w_top_tot + length + C(party_group)\", data=df).fit()\n","\n","    print(f\"\\nRDD Discontinuity Test (Using 'party_group') - {system_name} ({sex_category}):\")\n","    print(model.summary())\n","\n","    return model\n","\n","# Run RDD models with new party grouping\n","model_rdd_commission_men = test_rdd_significance_with_party(df_commission_rdd[df_commission_rdd['sex'] == 'male'], \"European Commission\", \"Men\")\n","model_rdd_commission_women = test_rdd_significance_with_party(df_commission_rdd[df_commission_rdd['sex'] == 'female'], \"European Commission\", \"Women\")\n","\n","model_rdd_bundestag_men = test_rdd_significance_with_party(df_bundestag_rdd[df_bundestag_rdd['sex'] == 'male'], \"German Bundestag\", \"Men\")\n","model_rdd_bundestag_women = test_rdd_significance_with_party(df_bundestag_rdd[df_bundestag_rdd['sex'] == 'female'], \"German Bundestag\", \"Women\")\n"],"metadata":{"id":"s4odcYuKwWFn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","from itertools import combinations\n","from scipy.spatial.distance import euclidean\n","\n","# Extract 'year' from 'date' and create time bins\n","df_commission_rdd[\"year\"] = df_commission_rdd[\"date\"].dt.year\n","df_bundestag_rdd[\"year\"] = df_bundestag_rdd[\"date\"].dt.year\n","\n","# Define 10-year and 5-year bins\n","df_commission_rdd[\"year_bin_10\"] = (df_commission_rdd[\"year\"] // 10) * 10\n","df_bundestag_rdd[\"year_bin_10\"] = (df_bundestag_rdd[\"year\"] // 10) * 10\n","\n","df_commission_rdd[\"year_bin_5\"] = (df_commission_rdd[\"year\"] // 5) * 5\n","df_bundestag_rdd[\"year_bin_5\"] = (df_bundestag_rdd[\"year\"] // 5) * 5\n","\n","# Check bins\n","print(\"Unique 10-year bins (Commission):\", df_commission_rdd[\"year_bin_10\"].unique())\n","print(\"Unique 10-year bins (Bundestag):\", df_bundestag_rdd[\"year_bin_10\"].unique())\n"],"metadata":{"id":"ZbIaglF3xt6n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check columns in both datasets\n","print(\"Columns in df_commission_rdd:\", df_commission_rdd.columns)\n","print(\"Columns in df_bundestag_rdd:\", df_bundestag_rdd.columns)\n"],"metadata":{"id":"fZCiUqN20Dha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load datasets\n","df_commission_rdd = pd.read_csv(\"/content/drive/My Drive/final_data_cleaned.csv\")\n","df_bundestag_rdd = pd.read_csv(\"/content/drive/My Drive/germanoptimized_speeches_with_topics_updated.csv\")\n","\n","# Convert 'date' column to datetime format\n","df_commission_rdd['date'] = pd.to_datetime(df_commission_rdd['date'], errors='coerce')\n","df_bundestag_rdd['date'] = pd.to_datetime(df_bundestag_rdd['date'], errors='coerce')\n","\n","# Confirm loading\n","print(\"\\n Datasets reloaded successfully!\")\n"],"metadata":{"id":"1Gjw09Qx1ooS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define event dates\n","event_commission = pd.Timestamp(\"2019-12-01\")\n","event_bundestag = pd.Timestamp(\"2005-11-01\")\n","\n","# Calculate actual dates from time_to_event\n","df_commission_rdd[\"date\"] = event_commission + pd.to_timedelta(df_commission_rdd[\"time_to_event\"], unit=\"D\")\n","df_bundestag_rdd[\"date\"] = event_bundestag + pd.to_timedelta(df_bundestag_rdd[\"time_to_event\"], unit=\"D\")\n","\n","# Extract year and define 10-year and 5-year bins\n","df_commission_rdd[\"year\"] = df_commission_rdd[\"date\"].dt.year\n","df_bundestag_rdd[\"year\"] = df_bundestag_rdd[\"date\"].dt.year\n","\n","df_commission_rdd[\"year_bin_10\"] = (df_commission_rdd[\"year\"] // 10) * 10\n","df_bundestag_rdd[\"year_bin_10\"] = (df_bundestag_rdd[\"year\"] // 10) * 10\n","\n","df_commission_rdd[\"year_bin_5\"] = (df_commission_rdd[\"year\"] // 5) * 5\n","df_bundestag_rdd[\"year_bin_5\"] = (df_bundestag_rdd[\"year\"] // 5) * 5\n","\n","# Verify the calculations\n","df_commission_rdd[[\"time_to_event\", \"date\", \"year\", \"year_bin_10\", \"year_bin_5\"]].head(), \\\n","df_bundestag_rdd[[\"time_to_event\", \"date\", \"year\", \"year_bin_10\", \"year_bin_5\"]].head()\n"],"metadata":{"id":"Zhqt4lAH293i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check available columns\n","print(\"Columns in df_commission_rdd:\", df_commission_rdd.columns)\n","print(\"Columns in df_bundestag_rdd:\", df_bundestag_rdd.columns)\n"],"metadata":{"id":"xVDtjZdf3LKN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure 'date' is in datetime format\n","df_commission_rdd[\"date\"] = pd.to_datetime(df_commission_rdd[\"date\"], errors='coerce')\n","df_bundestag_rdd[\"date\"] = pd.to_datetime(df_bundestag_rdd[\"date\"], errors='coerce')\n","\n","# Define event dates\n","event_commission = pd.Timestamp(\"2019-12-01\")\n","event_bundestag = pd.Timestamp(\"2005-11-01\")\n","\n","# Calculate time_to_event (days before or after the event)\n","df_commission_rdd[\"time_to_event\"] = (df_commission_rdd[\"date\"] - event_commission).dt.days\n","df_bundestag_rdd[\"time_to_event\"] = (df_bundestag_rdd[\"date\"] - event_bundestag).dt.days\n","\n","# Verify calculations\n","df_commission_rdd[[\"date\", \"time_to_event\"]].head(), df_bundestag_rdd[[\"date\", \"time_to_event\"]].head()\n"],"metadata":{"id":"zcCRl9753bHq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract the actual year from the date column\n","df_commission_rdd[\"year\"] = df_commission_rdd[\"date\"].dt.year\n","df_bundestag_rdd[\"year\"] = df_bundestag_rdd[\"date\"].dt.year\n","\n","# Create 10-year bins\n","df_commission_rdd[\"year_bin_10\"] = (df_commission_rdd[\"year\"] // 10) * 10\n","df_bundestag_rdd[\"year_bin_10\"] = (df_bundestag_rdd[\"year\"] // 10) * 10\n","\n","# Create 5-year bins\n","df_commission_rdd[\"year_bin_5\"] = (df_commission_rdd[\"year\"] // 5) * 5\n","df_bundestag_rdd[\"year_bin_5\"] = (df_bundestag_rdd[\"year\"] // 5) * 5\n","\n","# Verify results\n","df_commission_rdd[[\"date\", \"time_to_event\", \"year\", \"year_bin_10\", \"year_bin_5\"]].head(), \\\n","df_bundestag_rdd[[\"date\", \"time_to_event\", \"year\", \"year_bin_10\", \"year_bin_5\"]].head()\n"],"metadata":{"id":"9VH8K8H33l64"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","from itertools import combinations\n","from scipy.spatial.distance import euclidean\n","\n","# For the Commission dataset, the party variable is labeled \"European Party_speakerinfo\"\n","rename_dict = {\n","    'European Party_speakerinfo': 'party',   # Note: space instead of dot\n","    'Sex_speakerinfo': 'sex'\n","}\n","if \"European Party_speakerinfo\" in df_commission_rdd.columns:\n","    df_commission_rdd.rename(columns=rename_dict, inplace=True)\n","else:\n","    print(\"Error: Cannot find the column 'European Party_speakerinfo' in the Commission dataset.\")\n","\n","# For the Bundestag dataset, check if 'party' exists; if not, rename if possible (adjust if needed)\n","if \"party\" not in df_bundestag_rdd.columns:\n","    if \"European Party_speakerinfo\" in df_bundestag_rdd.columns:\n","        df_bundestag_rdd.rename(columns={'European Party_speakerinfo': 'party'}, inplace=True)\n","    else:\n","        print(\"Warning: 'party' column not found in the Bundestag dataset. Please verify the column name.\")\n","\n","# Recode party names using the party_mapping dictionary for both datasets\n","party_mapping = {\n","    'PES': 'PES',\n","    'PES[34]': 'PES',\n","    'PES\\xa0/': 'PES',  # Handles special character issues\n","    'ALDE': 'ALDE',\n","    'ALDE[23]': 'ALDE',\n","    'ALDE[25]': 'ALDE',\n","    'ALDE[5]': 'ALDE',\n","    'ALDE[32]': 'ALDE',\n","    'ALDE[38]': 'ALDE',\n","    'EPP': 'EPP',\n","    'csu': 'EPP',       # Map CSU to EPP\n","    'EGP': 'EGP',\n","    'ECR': 'ECR',\n","    'ECR[41]': 'ECR'\n","}\n","\n","df_commission_rdd[\"party\"] = df_commission_rdd[\"party\"].replace(party_mapping)\n","if \"party\" in df_bundestag_rdd.columns:\n","    df_bundestag_rdd[\"party\"] = df_bundestag_rdd[\"party\"].replace(party_mapping)\n","\n","\n","\n","# Ensure 'date' is in datetime format (errors='coerce' will turn invalid dates to NaT)\n","df_commission_rdd[\"date\"] = pd.to_datetime(df_commission_rdd[\"date\"], errors=\"coerce\")\n","df_bundestag_rdd[\"date\"] = pd.to_datetime(df_bundestag_rdd[\"date\"], errors=\"coerce\")\n","\n","# Define event dates:\n","# - European Commission event: December 1, 2019\n","# - German Bundestag event: November 1, 2005\n","event_commission = pd.Timestamp(\"2019-12-01\")\n","event_bundestag = pd.Timestamp(\"2005-11-01\")\n","\n","# Calculate time_to_event (number of days from event)\n","df_commission_rdd[\"time_to_event\"] = (df_commission_rdd[\"date\"] - event_commission).dt.days\n","df_bundestag_rdd[\"time_to_event\"] = (df_bundestag_rdd[\"date\"] - event_bundestag).dt.days\n","\n","# Extract year from date\n","df_commission_rdd[\"year\"] = df_commission_rdd[\"date\"].dt.year\n","df_bundestag_rdd[\"year\"] = df_bundestag_rdd[\"date\"].dt.year\n","\n","# Create 10-year bins and 5-year bins\n","df_commission_rdd[\"year_bin_10\"] = (df_commission_rdd[\"year\"] // 10) * 10\n","df_bundestag_rdd[\"year_bin_10\"] = (df_bundestag_rdd[\"year\"] // 10) * 10\n","\n","df_commission_rdd[\"year_bin_5\"] = (df_commission_rdd[\"year\"] // 5) * 5\n","df_bundestag_rdd[\"year_bin_5\"] = (df_bundestag_rdd[\"year\"] // 5) * 5\n","\n","# Optional: Verify the new variables\n","print(df_commission_rdd[[\"date\", \"time_to_event\", \"year\", \"year_bin_10\", \"year_bin_5\"]].head())\n","print(df_bundestag_rdd[[\"date\", \"time_to_event\", \"year\", \"year_bin_10\", \"year_bin_5\"]].head())\n","\n","\n","\n","# For analysis, we use the datasets as df_commission and df_bundestag:\n","df_commission = df_commission_rdd.copy()\n","df_bundestag = df_bundestag_rdd.copy()\n","\n","def run_logistic_by_time(df, time_var, institution):\n","    results = {}\n","    for time_period in sorted(df[time_var].unique()):\n","        subset = df[df[time_var] == time_period]\n","        if subset.shape[0] > 10:  # Only run if enough observations\n","            model = smf.logit(\"claimbinary ~ C(sex) + C(party) + length + w_top_tot\", data=subset).fit(disp=False)\n","            results[time_period] = model\n","        else:\n","            print(f\"Skipping {institution} {time_period} due to insufficient data.\")\n","    print(f\"Logistic regressions completed for {institution} ({time_var}).\")\n","    return results\n","\n","# Run regressions for 10-year bins and 5-year bins for each institution:\n","models_commission_10 = run_logistic_by_time(df_commission, \"year_bin_10\", \"European Commission\")\n","models_commission_5 = run_logistic_by_time(df_commission, \"year_bin_5\", \"European Commission\")\n","models_bundestag_10 = run_logistic_by_time(df_bundestag, \"year_bin_10\", \"German Bundestag\")\n","models_bundestag_5 = run_logistic_by_time(df_bundestag, \"year_bin_5\", \"German Bundestag\")\n","\n","\n","\n","def wald_test_over_time(models, institution):\n","    test_results = {}\n","    time_combinations = list(combinations(models.keys(), 2))\n","    for (t1, t2) in time_combinations:\n","        model1 = models[t1]\n","        model2 = models[t2]\n","        common_params = list(set(model1.params.index) & set(model2.params.index))\n","        # Compute the Wald statistic over the common parameters\n","        diff = model1.params[common_params] - model2.params[common_params]\n","        var_diff = model1.bse[common_params]**2 + model2.bse[common_params]**2\n","        wald_stat = sum((diff**2) / var_diff)\n","        df_param = len(common_params)\n","        p_value = 1 - sm.stats.chi2.sf(wald_stat, df=df_param)\n","        test_results[(t1, t2)] = p_value\n","    print(f\"Wald tests completed for {institution}.\")\n","    return test_results\n","\n","wald_commission_10 = wald_test_over_time(models_commission_10, \"European Commission\")\n","wald_commission_5 = wald_test_over_time(models_commission_5, \"European Commission\")\n","wald_bundestag_10 = wald_test_over_time(models_bundestag_10, \"German Bundestag\")\n","wald_bundestag_5 = wald_test_over_time(models_bundestag_5, \"German Bundestag\")\n","\n","\n","\n","def find_most_similar_periods(models_commission, models_bundestag):\n","    similarity_results = {}\n","    for comm_time, comm_model in models_commission.items():\n","        best_match = None\n","        min_distance = float(\"inf\")\n","        for bund_time, bund_model in models_bundestag.items():\n","            common_params = list(set(comm_model.params.index) & set(bund_model.params.index))\n","            if len(common_params) > 0:\n","                distance = euclidean(comm_model.params[common_params], bund_model.params[common_params])\n","                if distance < min_distance:\n","                    min_distance = distance\n","                    best_match = bund_time\n","        similarity_results[comm_time] = best_match\n","    print(\"Similarity analysis completed between European Commission and German Bundestag.\")\n","    return similarity_results\n","\n","similar_periods_10 = find_most_similar_periods(models_commission_10, models_bundestag_10)\n","similar_periods_5 = find_most_similar_periods(models_commission_5, models_bundestag_5)\n","\n","# Display the similarity results\n","print(\"Most similar time periods (10-year bins):\", similar_periods_10)\n","print(\"Most similar time periods (5-year bins):\", similar_periods_5)\n"],"metadata":{"id":"pUUy4SBw4jDd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","from itertools import combinations\n","from scipy.spatial.distance import euclidean\n","from scipy.stats import chi2\n","\n","\n","# For the European Commission dataset, check for the party column.\n","if \"European Party_speakerinfo\" in df_commission_rdd.columns:\n","    df_commission_rdd.rename(columns={'European Party_speakerinfo': 'party',\n","                                       'Sex_speakerinfo': 'sex'}, inplace=True)\n","else:\n","    print(\"Note: 'European Party_speakerinfo' not found â€“ using existing 'party' column in Commission dataset.\")\n","\n","# For the Bundestag dataset, if 'party' is missing, try renaming\n","if \"party\" not in df_bundestag_rdd.columns:\n","    if \"European Party_speakerinfo\" in df_bundestag_rdd.columns:\n","        df_bundestag_rdd.rename(columns={'European Party_speakerinfo': 'party'}, inplace=True)\n","    else:\n","        print(\"Warning: 'party' column not found in Bundestag dataset.\")\n","\n","# Recode party names using party_mapping for both datasets\n","party_mapping = {\n","    'PES': 'PES',\n","    'PES[34]': 'PES',\n","    'PES\\xa0/': 'PES',  # Handles special character issues\n","    'ALDE': 'ALDE',\n","    'ALDE[23]': 'ALDE',\n","    'ALDE[25]': 'ALDE',\n","    'ALDE[5]': 'ALDE',\n","    'ALDE[32]': 'ALDE',\n","    'ALDE[38]': 'ALDE',\n","    'EPP': 'EPP',\n","    'csu': 'EPP',       # Map CSU to EPP\n","    'EGP': 'EGP',\n","    'ECR': 'ECR',\n","    'ECR[41]': 'ECR'\n","}\n","if \"party\" in df_commission_rdd.columns:\n","    df_commission_rdd[\"party\"] = df_commission_rdd[\"party\"].replace(party_mapping)\n","if \"party\" in df_bundestag_rdd.columns:\n","    df_bundestag_rdd[\"party\"] = df_bundestag_rdd[\"party\"].replace(party_mapping)\n","\n","\n","# Ensure 'date' is datetime\n","df_commission_rdd[\"date\"] = pd.to_datetime(df_commission_rdd[\"date\"], errors=\"coerce\")\n","df_bundestag_rdd[\"date\"] = pd.to_datetime(df_bundestag_rdd[\"date\"], errors=\"coerce\")\n","\n","# Define event dates:\n","#   - European Commission event: December 1, 2019\n","#   - German Bundestag event: November 1, 2005\n","event_commission = pd.Timestamp(\"2019-12-01\")\n","event_bundestag = pd.Timestamp(\"2005-11-01\")\n","\n","# Calculate time_to_event (days from event)\n","df_commission_rdd[\"time_to_event\"] = (df_commission_rdd[\"date\"] - event_commission).dt.days\n","df_bundestag_rdd[\"time_to_event\"] = (df_bundestag_rdd[\"date\"] - event_bundestag).dt.days\n","\n","# Extract year from date\n","df_commission_rdd[\"year\"] = df_commission_rdd[\"date\"].dt.year\n","df_bundestag_rdd[\"year\"] = df_bundestag_rdd[\"date\"].dt.year\n","\n","# Create 10-year and 5-year bins\n","df_commission_rdd[\"year_bin_10\"] = (df_commission_rdd[\"year\"] // 10) * 10\n","df_bundestag_rdd[\"year_bin_10\"] = (df_bundestag_rdd[\"year\"] // 10) * 10\n","\n","df_commission_rdd[\"year_bin_5\"] = (df_commission_rdd[\"year\"] // 5) * 5\n","df_bundestag_rdd[\"year_bin_5\"] = (df_bundestag_rdd[\"year\"] // 5) * 5\n","\n","# Verify the new variables\n","print(\"Commission dataset sample:\")\n","print(df_commission_rdd[[\"date\", \"time_to_event\", \"year\", \"year_bin_10\", \"year_bin_5\"]].head())\n","print(\"\\nBundestag dataset sample:\")\n","print(df_bundestag_rdd[[\"date\", \"time_to_event\", \"year\", \"year_bin_10\", \"year_bin_5\"]].head())\n","\n","# work with df_commission and df_bundestag as copies of the respective datasets.\n","df_commission = df_commission_rdd.copy()\n","df_bundestag = df_bundestag_rdd.copy()\n","\n","# Ensure the dependent variable 'claimbinary' is numeric and one-dimensional\n","df_commission[\"claimbinary\"] = pd.to_numeric(df_commission[\"claimbinary\"], errors=\"coerce\")\n","df_bundestag[\"claimbinary\"] = pd.to_numeric(df_bundestag[\"claimbinary\"], errors=\"coerce\").squeeze()\n","\n","# Keep only rows where claimbinary is 0 or 1\n","df_commission = df_commission[df_commission[\"claimbinary\"].isin([0, 1])]\n","df_bundestag = df_bundestag[df_bundestag[\"claimbinary\"].isin([0, 1])]\n","\n","\n","def run_logistic_by_time(df, time_var, institution):\n","    results = {}\n","    for time_period in sorted(df[time_var].unique()):\n","        subset = df[df[time_var] == time_period]\n","        if subset.shape[0] > 10:\n","            try:\n","                model = smf.logit(\"claimbinary ~ C(sex) + C(party) + length + w_top_tot\", data=subset).fit(disp=False)\n","                results[time_period] = model\n","            except Exception as e:\n","                print(f\"Error in {institution} {time_period}: {e}. Skipping this time bin.\")\n","        else:\n","            print(f\"Skipping {institution} {time_period} due to insufficient data.\")\n","    print(f\"Logistic regressions completed for {institution} ({time_var}).\")\n","    return results\n","\n","# Run regressions for 10-year bins and 5-year bins\n","models_commission_10 = run_logistic_by_time(df_commission, \"year_bin_10\", \"European Commission\")\n","models_commission_5 = run_logistic_by_time(df_commission, \"year_bin_5\", \"European Commission\")\n","models_bundestag_10 = run_logistic_by_time(df_bundestag, \"year_bin_10\", \"German Bundestag\")\n","models_bundestag_5 = run_logistic_by_time(df_bundestag, \"year_bin_5\", \"German Bundestag\")\n","\n","\n","def wald_test_over_time(models, institution):\n","    test_results = {}\n","    time_combinations = list(combinations(models.keys(), 2))\n","    for (t1, t2) in time_combinations:\n","        model1 = models[t1]\n","        model2 = models[t2]\n","        common_params = list(set(model1.params.index) & set(model2.params.index))\n","        if len(common_params) == 0:\n","            continue\n","        diff = model1.params[common_params] - model2.params[common_params]\n","        var_diff = model1.bse[common_params]**2 + model2.bse[common_params]**2\n","        wald_stat = sum((diff**2) / var_diff)\n","        df_param = len(common_params)\n","        p_value = 1 - chi2.sf(wald_stat, df=df_param)\n","        test_results[(t1, t2)] = p_value\n","    print(f\"Wald tests completed for {institution}.\")\n","    return test_results\n","\n","wald_commission_10 = wald_test_over_time(models_commission_10, \"European Commission\")\n","wald_commission_5 = wald_test_over_time(models_commission_5, \"European Commission\")\n","wald_bundestag_10 = wald_test_over_time(models_bundestag_10, \"German Bundestag\")\n","wald_bundestag_5 = wald_test_over_time(models_bundestag_5, \"German Bundestag\")\n","\n","\n","def find_most_similar_periods(models_commission, models_bundestag):\n","    similarity_results = {}\n","    for comm_time, comm_model in models_commission.items():\n","        best_match = None\n","        min_distance = float(\"inf\")\n","        for bund_time, bund_model in models_bundestag.items():\n","            common_params = list(set(comm_model.params.index) & set(bund_model.params.index))\n","            if len(common_params) > 0:\n","                distance = euclidean(comm_model.params[common_params], bund_model.params[common_params])\n","                if distance < min_distance:\n","                    min_distance = distance\n","                    best_match = bund_time\n","        similarity_results[comm_time] = best_match\n","    print(\"Similarity analysis completed between European Commission and German Bundestag.\")\n","    return similarity_results\n","\n","similar_periods_10 = find_most_similar_periods(models_commission_10, models_bundestag_10)\n","similar_periods_5 = find_most_similar_periods(models_commission_5, models_bundestag_5)\n","\n","# Display the similarity results\n","print(\"Most similar time periods (10-year bins):\", similar_periods_10)\n","print(\"Most similar time periods (5-year bins):\", similar_periods_5)\n"],"metadata":{"id":"SwmACPLw5nok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the data type and the first few rows of claimbinary in the Bundestag dataset\n","print(\"Claimbinary (Bundestag) dtype:\", df_bundestag[\"claimbinary\"].dtype)\n","print(\"First few values of claimbinary (Bundestag):\")\n","print(df_bundestag[\"claimbinary\"].head())\n","\n","# Check if there are duplicate column names for claimbinary\n","print(\"All columns in Bundestag dataset:\")\n","print(df_bundestag.columns.tolist())\n"],"metadata":{"id":"ZHA9F3F18bnp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","from itertools import combinations\n","from scipy.spatial.distance import euclidean\n","from scipy.stats import chi2\n","\n","\n","# For Commission dataset, rename \"European Party_speakerinfo\" if it exists; otherwise, use the existing 'party' column.\n","if \"European Party_speakerinfo\" in df_commission_rdd.columns:\n","    df_commission_rdd.rename(columns={'European Party_speakerinfo': 'party',\n","                                      'Sex_speakerinfo': 'sex'}, inplace=True)\n","else:\n","    print(\"Note: 'European Party_speakerinfo' not found â€“ using existing 'party' column in Commission dataset.\")\n","\n","# For Bundestag dataset, if 'party' is missing, try renaming (adjust if needed)\n","if \"party\" not in df_bundestag_rdd.columns:\n","    if \"European Party_speakerinfo\" in df_bundestag_rdd.columns:\n","        df_bundestag_rdd.rename(columns={'European Party_speakerinfo': 'party'}, inplace=True)\n","    else:\n","        print(\"Warning: 'party' column not found in Bundestag dataset.\")\n","\n","# Recode party names using the party_mapping dictionary for both datasets\n","party_mapping = {\n","    'PES': 'PES',\n","    'PES[34]': 'PES',\n","    'PES\\xa0/': 'PES',  # Handles special character issues\n","    'ALDE': 'ALDE',\n","    'ALDE[23]': 'ALDE',\n","    'ALDE[25]': 'ALDE',\n","    'ALDE[5]': 'ALDE',\n","    'ALDE[32]': 'ALDE',\n","    'ALDE[38]': 'ALDE',\n","    'EPP': 'EPP',\n","    'csu': 'EPP',       # Map CSU to EPP\n","    'EGP': 'EGP',\n","    'ECR': 'ECR',\n","    'ECR[41]': 'ECR'\n","}\n","if \"party\" in df_commission_rdd.columns:\n","    df_commission_rdd[\"party\"] = df_commission_rdd[\"party\"].replace(party_mapping)\n","if \"party\" in df_bundestag_rdd.columns:\n","    df_bundestag_rdd[\"party\"] = df_bundestag_rdd[\"party\"].replace(party_mapping)\n","\n","\n","# Ensure 'date' is in datetime format\n","df_commission_rdd[\"date\"] = pd.to_datetime(df_commission_rdd[\"date\"], errors=\"coerce\")\n","df_bundestag_rdd[\"date\"] = pd.to_datetime(df_bundestag_rdd[\"date\"], errors=\"coerce\")\n","\n","# Define event dates:\n","#   - European Commission event: December 1, 2019\n","#   - German Bundestag event: November 1, 2005\n","event_commission = pd.Timestamp(\"2019-12-01\")\n","event_bundestag = pd.Timestamp(\"2005-11-01\")\n","\n","# Calculate time_to_event (in days)\n","df_commission_rdd[\"time_to_event\"] = (df_commission_rdd[\"date\"] - event_commission).dt.days\n","df_bundestag_rdd[\"time_to_event\"] = (df_bundestag_rdd[\"date\"] - event_bundestag).dt.days\n","\n","# Extract year from the date\n","df_commission_rdd[\"year\"] = df_commission_rdd[\"date\"].dt.year\n","df_bundestag_rdd[\"year\"] = df_bundestag_rdd[\"date\"].dt.year\n","\n","# Create 10-year and 5-year bins\n","df_commission_rdd[\"year_bin_10\"] = (df_commission_rdd[\"year\"] // 10) * 10\n","df_bundestag_rdd[\"year_bin_10\"] = (df_bundestag_rdd[\"year\"] // 10) * 10\n","\n","df_commission_rdd[\"year_bin_5\"] = (df_commission_rdd[\"year\"] // 5) * 5\n","df_bundestag_rdd[\"year_bin_5\"] = (df_bundestag_rdd[\"year\"] // 5) * 5\n","\n","# Optional: Verify the new variables\n","print(\"Commission dataset sample:\")\n","print(df_commission_rdd[[\"date\", \"time_to_event\", \"year\", \"year_bin_10\", \"year_bin_5\"]].head())\n","print(\"\\nBundestag dataset sample:\")\n","print(df_bundestag_rdd[[\"date\", \"time_to_event\", \"year\", \"year_bin_10\", \"year_bin_5\"]].head())\n","\n","\n","# Define df_commission and df_bundestag as copies\n","df_commission = df_commission_rdd.copy()\n","df_bundestag = df_bundestag_rdd.copy()\n","\n","# Convert the dependent variable 'claimbinary' to numeric and then to integer\n","df_commission[\"claimbinary\"] = pd.to_numeric(df_commission[\"claimbinary\"], errors=\"coerce\").astype(int)\n","df_bundestag[\"claimbinary\"] = pd.to_numeric(df_bundestag[\"claimbinary\"], errors=\"coerce\").astype(int)\n","\n","# Keep only rows where claimbinary is 0 or 1\n","df_commission = df_commission[df_commission[\"claimbinary\"].isin([0, 1])]\n","df_bundestag = df_bundestag[df_bundestag[\"claimbinary\"].isin([0, 1])]\n","\n","\n","def run_logistic_by_time(df, time_var, institution):\n","    results = {}\n","    for time_period in sorted(df[time_var].unique()):\n","        subset = df[df[time_var] == time_period]\n","        if subset.shape[0] > 10:\n","            try:\n","                model = smf.logit(\"claimbinary ~ C(sex) + length + w_top_tot\", data=subset).fit(disp=False)\n","                results[time_period] = model\n","            except Exception as e:\n","                print(f\"Error in {institution} {time_period}: {e}. Skipping this time bin.\")\n","        else:\n","            print(f\"Skipping {institution} {time_period} due to insufficient data.\")\n","    print(f\"Logistic regressions completed for {institution} ({time_var}).\")\n","    return results\n","\n","# Run regressions for 10-year bins and 5-year bins for each institution\n","models_commission_10 = run_logistic_by_time(df_commission, \"year_bin_10\", \"European Commission\")\n","models_commission_5 = run_logistic_by_time(df_commission, \"year_bin_5\", \"European Commission\")\n","models_bundestag_10 = run_logistic_by_time(df_bundestag, \"year_bin_10\", \"German Bundestag\")\n","models_bundestag_5 = run_logistic_by_time(df_bundestag, \"year_bin_5\", \"German Bundestag\")\n","\n","\n","def wald_test_over_time(models, institution):\n","    test_results = {}\n","    time_combinations = list(combinations(models.keys(), 2))\n","    for (t1, t2) in time_combinations:\n","        model1 = models[t1]\n","        model2 = models[t2]\n","        common_params = list(set(model1.params.index) & set(model2.params.index))\n","        if len(common_params) == 0:\n","            continue\n","        diff = model1.params[common_params] - model2.params[common_params]\n","        var_diff = model1.bse[common_params]**2 + model2.bse[common_params]**2\n","        wald_stat = sum((diff**2) / var_diff)\n","        df_param = len(common_params)\n","        p_value = 1 - chi2.sf(wald_stat, df=df_param)\n","        test_results[(t1, t2)] = p_value\n","    print(f\"Wald tests completed for {institution}.\")\n","    return test_results\n","\n","wald_commission_10 = wald_test_over_time(models_commission_10, \"European Commission\")\n","wald_commission_5 = wald_test_over_time(models_commission_5, \"European Commission\")\n","wald_bundestag_10 = wald_test_over_time(models_bundestag_10, \"German Bundestag\")\n","wald_bundestag_5 = wald_test_over_time(models_bundestag_5, \"German Bundestag\")\n","\n","\n","def find_most_similar_periods(models_commission, models_bundestag):\n","    similarity_results = {}\n","    for comm_time, comm_model in models_commission.items():\n","        best_match = None\n","        min_distance = float(\"inf\")\n","        for bund_time, bund_model in models_bundestag.items():\n","            common_params = list(set(comm_model.params.index) & set(bund_model.params.index))\n","            if len(common_params) > 0:\n","                distance = euclidean(comm_model.params[common_params], bund_model.params[common_params])\n","                if distance < min_distance:\n","                    min_distance = distance\n","                    best_match = bund_time\n","        similarity_results[comm_time] = best_match\n","    print(\"Similarity analysis completed between European Commission and German Bundestag.\")\n","    return similarity_results\n","\n","similar_periods_10 = find_most_similar_periods(models_commission_10, models_bundestag_10)\n","similar_periods_5 = find_most_similar_periods(models_commission_5, models_bundestag_5)\n","\n","# Display the similarity results\n","print(\"Most similar time periods (10-year bins):\", similar_periods_10)\n","print(\"Most similar time periods (5-year bins):\", similar_periods_5)\n"],"metadata":{"id":"5Mxf8Q_79Ekb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","from itertools import combinations\n","from scipy.spatial.distance import euclidean\n","from scipy.stats import chi2\n","\n","\n","# For Commission dataset, rename \"European Party_speakerinfo\" if it exists; otherwise, use the existing 'party' column.\n","if \"European Party_speakerinfo\" in df_commission_rdd.columns:\n","    df_commission_rdd.rename(columns={'European Party_speakerinfo': 'party',\n","                                      'Sex_speakerinfo': 'sex'}, inplace=True)\n","else:\n","    print(\"Note: 'European Party_speakerinfo' not found â€“ using existing 'party' column in Commission dataset.\")\n","\n","# For Bundestag dataset, if 'party' is missing, try renaming (adjust if needed)\n","if \"party\" not in df_bundestag_rdd.columns:\n","    if \"European Party_speakerinfo\" in df_bundestag_rdd.columns:\n","        df_bundestag_rdd.rename(columns={'European Party_speakerinfo': 'party'}, inplace=True)\n","    else:\n","        print(\"Warning: 'party' column not found in Bundestag dataset.\")\n","\n","# Recode party names using the party_mapping dictionary for both datasets\n","party_mapping = {\n","    'PES': 'PES',\n","    'PES[34]': 'PES',\n","    'PES\\xa0/': 'PES',  # Handles special character issues\n","    'ALDE': 'ALDE',\n","    'ALDE[23]': 'ALDE',\n","    'ALDE[25]': 'ALDE',\n","    'ALDE[5]': 'ALDE',\n","    'ALDE[32]': 'ALDE',\n","    'ALDE[38]': 'ALDE',\n","    'EPP': 'EPP',\n","    'csu': 'EPP',       # Map CSU to EPP\n","    'EGP': 'EGP',\n","    'ECR': 'ECR',\n","    'ECR[41]': 'ECR'\n","}\n","if \"party\" in df_commission_rdd.columns:\n","    df_commission_rdd[\"party\"] = df_commission_rdd[\"party\"].replace(party_mapping)\n","if \"party\" in df_bundestag_rdd.columns:\n","    df_bundestag_rdd[\"party\"] = df_bundestag_rdd[\"party\"].replace(party_mapping)\n","\n","\n","# Ensure 'date' is in datetime format\n","df_commission_rdd[\"date\"] = pd.to_datetime(df_commission_rdd[\"date\"], errors=\"coerce\")\n","df_bundestag_rdd[\"date\"] = pd.to_datetime(df_bundestag_rdd[\"date\"], errors=\"coerce\")\n","\n","# Define event dates:\n","#   - European Commission event: December 1, 2019\n","#   - German Bundestag event: November 1, 2005\n","event_commission = pd.Timestamp(\"2019-12-01\")\n","event_bundestag = pd.Timestamp(\"2005-11-01\")\n","\n","# Calculate time_to_event (in days)\n","df_commission_rdd[\"time_to_event\"] = (df_commission_rdd[\"date\"] - event_commission).dt.days\n","df_bundestag_rdd[\"time_to_event\"] = (df_bundestag_rdd[\"date\"] - event_bundestag).dt.days\n","\n","# Extract year from the date\n","df_commission_rdd[\"year\"] = df_commission_rdd[\"date\"].dt.year\n","df_bundestag_rdd[\"year\"] = df_bundestag_rdd[\"date\"].dt.year\n","\n","# Create 10-year and 5-year bins\n","df_commission_rdd[\"year_bin_2\"] = (df_commission_rdd[\"year\"] // 2) * 2\n","df_bundestag_rdd[\"year_bin_2\"] = (df_bundestag_rdd[\"year\"] // 2) * 2\n","\n","df_commission_rdd[\"year_bin_5\"] = (df_commission_rdd[\"year\"] // 5) * 5\n","df_bundestag_rdd[\"year_bin_5\"] = (df_bundestag_rdd[\"year\"] // 5) * 5\n","\n","# Optional: Verify the new variables\n","print(\"Commission dataset sample:\")\n","print(df_commission_rdd[[\"date\", \"time_to_event\", \"year\", \"year_bin_2\", \"year_bin_5\"]].head())\n","print(\"\\nBundestag dataset sample:\")\n","print(df_bundestag_rdd[[\"date\", \"time_to_event\", \"year\", \"year_bin_2\", \"year_bin_5\"]].head())\n","\n","\n","# Define df_commission and df_bundestag as copies\n","df_commission = df_commission_rdd.copy()\n","df_bundestag = df_bundestag_rdd.copy()\n","\n","# Convert the dependent variable 'claimbinary' to numeric and then to integer\n","df_commission[\"claimbinary\"] = pd.to_numeric(df_commission[\"claimbinary\"], errors=\"coerce\").astype(int)\n","df_bundestag[\"claimbinary\"] = pd.to_numeric(df_bundestag[\"claimbinary\"], errors=\"coerce\").astype(int)\n","\n","# Keep only rows where claimbinary is 0 or 1\n","df_commission = df_commission[df_commission[\"claimbinary\"].isin([0, 1])]\n","df_bundestag = df_bundestag[df_bundestag[\"claimbinary\"].isin([0, 1])]\n","\n","\n","def run_logistic_by_time(df, time_var, institution):\n","    results = {}\n","    for time_period in sorted(df[time_var].unique()):\n","        subset = df[df[time_var] == time_period]\n","        if subset.shape[0] > 10:\n","            try:\n","                model = smf.logit(\"claimbinary ~ C(sex) + length + w_top_tot\", data=subset).fit(disp=False)\n","                results[time_period] = model\n","            except Exception as e:\n","                print(f\"Error in {institution} {time_period}: {e}. Skipping this time bin.\")\n","        else:\n","            print(f\"Skipping {institution} {time_period} due to insufficient data.\")\n","    print(f\"Logistic regressions completed for {institution} ({time_var}).\")\n","    return results\n","\n","# Run regressions for 10-year bins and 5-year bins for each institution\n","models_commission_2 = run_logistic_by_time(df_commission, \"year_bin_2\", \"European Commission\")\n","models_commission_5 = run_logistic_by_time(df_commission, \"year_bin_5\", \"European Commission\")\n","models_bundestag_2 = run_logistic_by_time(df_bundestag, \"year_bin_2\", \"German Bundestag\")\n","models_bundestag_5 = run_logistic_by_time(df_bundestag, \"year_bin_5\", \"German Bundestag\")\n","\n","def wald_test_over_time(models, institution):\n","    test_results = {}\n","    time_combinations = list(combinations(models.keys(), 2))\n","    for (t1, t2) in time_combinations:\n","        model1 = models[t1]\n","        model2 = models[t2]\n","        common_params = list(set(model1.params.index) & set(model2.params.index))\n","        if len(common_params) == 0:\n","            continue\n","        diff = model1.params[common_params] - model2.params[common_params]\n","        var_diff = model1.bse[common_params]**2 + model2.bse[common_params]**2\n","        wald_stat = sum((diff**2) / var_diff)\n","        df_param = len(common_params)\n","        p_value = 1 - chi2.sf(wald_stat, df=df_param)\n","        test_results[(t1, t2)] = p_value\n","    print(f\"Wald tests completed for {institution}.\")\n","    return test_results\n","\n","wald_commission_2 = wald_test_over_time(models_commission_2, \"European Commission\")\n","wald_commission_5 = wald_test_over_time(models_commission_5, \"European Commission\")\n","wald_bundestag_2 = wald_test_over_time(models_bundestag_2, \"German Bundestag\")\n","wald_bundestag_5 = wald_test_over_time(models_bundestag_5, \"German Bundestag\")\n","\n","def find_most_similar_periods(models_commission, models_bundestag):\n","    similarity_results = {}\n","    for comm_time, comm_model in models_commission.items():\n","        best_match = None\n","        min_distance = float(\"inf\")\n","        for bund_time, bund_model in models_bundestag.items():\n","            common_params = list(set(comm_model.params.index) & set(bund_model.params.index))\n","            if len(common_params) > 0:\n","                distance = euclidean(comm_model.params[common_params], bund_model.params[common_params])\n","                if distance < min_distance:\n","                    min_distance = distance\n","                    best_match = bund_time\n","        similarity_results[comm_time] = best_match\n","    print(\"Similarity analysis completed between European Commission and German Bundestag.\")\n","    return similarity_results\n","\n","similar_periods_2 = find_most_similar_periods(models_commission_2, models_bundestag_2)\n","similar_periods_5 = find_most_similar_periods(models_commission_5, models_bundestag_5)\n","\n","# Display the similarity results\n","print(\"Most similar time periods (2-year bins):\", similar_periods_2)\n","print(\"Most similar time periods (5-year bins):\", similar_periods_5)\n"],"metadata":{"id":"Kwle3n7DEBWs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import statsmodels.api as sm\n","from statsmodels.discrete.count_model import ZeroInflatedNegativeBinomialP\n","import patsy\n","from itertools import combinations\n","from scipy.spatial.distance import euclidean\n","from scipy.stats import chi2\n","\n","\n","# For the Commission dataset, use the existing 'party' column (if \"European Party_speakerinfo\" is missing)\n","if \"European Party_speakerinfo\" in df_commission_rdd.columns:\n","    df_commission_rdd.rename(columns={'European Party_speakerinfo': 'party',\n","                                      'Sex_speakerinfo': 'sex'}, inplace=True)\n","else:\n","    print(\"Note: 'European Party_speakerinfo' not found â€“ using existing 'party' column in Commission dataset.\")\n","\n","# For the Bundestag dataset, if 'party' is missing, attempt renaming if possible.\n","if \"party\" not in df_bundestag_rdd.columns:\n","    if \"European Party_speakerinfo\" in df_bundestag_rdd.columns:\n","        df_bundestag_rdd.rename(columns={'European Party_speakerinfo': 'party'}, inplace=True)\n","    else:\n","        print(\"Warning: 'party' column not found in Bundestag dataset.\")\n","\n","# Recode party names using your provided party_mapping\n","party_mapping = {\n","    'PES': 'PES',\n","    'PES[34]': 'PES',\n","    'PES\\xa0/': 'PES',  # Handles special character issues\n","    'ALDE': 'ALDE',\n","    'ALDE[23]': 'ALDE',\n","    'ALDE[25]': 'ALDE',\n","    'ALDE[5]': 'ALDE',\n","    'ALDE[32]': 'ALDE',\n","    'ALDE[38]': 'ALDE',\n","    'EPP': 'EPP',\n","    'csu': 'EPP',       # Map CSU to EPP\n","    'EGP': 'EGP',\n","    'ECR': 'ECR',\n","    'ECR[41]': 'ECR'\n","}\n","\n","if \"party\" in df_commission_rdd.columns:\n","    df_commission_rdd[\"party\"] = df_commission_rdd[\"party\"].replace(party_mapping)\n","if \"party\" in df_bundestag_rdd.columns:\n","    df_bundestag_rdd[\"party\"] = df_bundestag_rdd[\"party\"].replace(party_mapping)\n","\n","\n","# Ensure 'date' is datetime\n","df_commission_rdd[\"date\"] = pd.to_datetime(df_commission_rdd[\"date\"], errors=\"coerce\")\n","df_bundestag_rdd[\"date\"] = pd.to_datetime(df_bundestag_rdd[\"date\"], errors=\"coerce\")\n","\n","# Define event dates:\n","#   - European Commission event: December 1, 2019\n","#   - German Bundestag event: November 1, 2005\n","event_commission = pd.Timestamp(\"2019-12-01\")\n","event_bundestag = pd.Timestamp(\"2005-11-01\")\n","\n","# Calculate time_to_event (in days)\n","df_commission_rdd[\"time_to_event\"] = (df_commission_rdd[\"date\"] - event_commission).dt.days\n","df_bundestag_rdd[\"time_to_event\"] = (df_bundestag_rdd[\"date\"] - event_bundestag).dt.days\n","\n","# Extract year from date\n","df_commission_rdd[\"year\"] = df_commission_rdd[\"date\"].dt.year\n","df_bundestag_rdd[\"year\"] = df_bundestag_rdd[\"date\"].dt.year\n","\n","# Create 10-year and 5-year bins\n","df_commission_rdd[\"year_bin_10\"] = (df_commission_rdd[\"year\"] // 10) * 10\n","df_bundestag_rdd[\"year_bin_10\"] = (df_bundestag_rdd[\"year\"] // 10) * 10\n","\n","df_commission_rdd[\"year_bin_5\"] = (df_commission_rdd[\"year\"] // 5) * 5\n","df_bundestag_rdd[\"year_bin_5\"] = (df_bundestag_rdd[\"year\"] // 5) * 5\n","\n","# Optional: Check samples\n","print(\"Commission dataset sample:\")\n","print(df_commission_rdd[[\"date\", \"time_to_event\", \"year\", \"year_bin_10\", \"year_bin_5\"]].head())\n","print(\"\\nBundestag dataset sample:\")\n","print(df_bundestag_rdd[[\"date\", \"time_to_event\", \"year\", \"year_bin_10\", \"year_bin_5\"]].head())\n","\n","\n","# Work with copies:\n","df_commission = df_commission_rdd.copy()\n","df_bundestag = df_bundestag_rdd.copy()\n","\n","# Convert the dependent variable 'claimcount' to numeric\n","df_commission[\"claimcount\"] = pd.to_numeric(df_commission[\"claimcount\"], errors=\"coerce\")\n","df_bundestag[\"claimcount\"] = pd.to_numeric(df_bundestag[\"claimcount\"], errors=\"coerce\")\n","\n","# Optionally, remove missing values in claimcount:\n","df_commission = df_commission.dropna(subset=[\"claimcount\"])\n","df_bundestag = df_bundestag.dropna(subset=[\"claimcount\"])\n","\n","\n","# use patsy to create design matrices and run ZINB regressions using ZeroInflatedNegativeBinomialP.\n","\n","from statsmodels.discrete.count_model import ZeroInflatedNegativeBinomialP\n","import patsy\n","\n","def run_zinb_by_time(df, time_var, institution):\n","    results = {}\n","    for time_period in sorted(df[time_var].unique()):\n","        subset = df[df[time_var] == time_period]\n","        if subset.shape[0] > 10:\n","            try:\n","                # Create design matrices using patsy\n","                # We use a formula for the count part.\n","                formula = \"claimcount ~ C(sex) + length + w_top_tot\"\n","                y, X = patsy.dmatrices(formula, data=subset, return_type=\"dataframe\")\n","                # For the inflation model, use only a constant.\n","                Z = pd.DataFrame({\"const\": 1}, index=X.index)\n","                # Fit the zero-inflated negative binomial model\n","                model = ZeroInflatedNegativeBinomialP(y, X, exog_infl=Z, inflation=\"logit\").fit(disp=0)\n","                results[time_period] = model\n","            except Exception as e:\n","                print(f\"ZINB Error in {institution} {time_period}: {e}. Skipping this time bin.\")\n","        else:\n","            print(f\"Skipping {institution} {time_period} due to insufficient data.\")\n","    print(f\"ZINB regressions completed for {institution} ({time_var}).\")\n","    return results\n","\n","# Run ZINB regressions for 10-year and 5-year bins\n","models_commission_zinb_10 = run_zinb_by_time(df_commission, \"year_bin_10\", \"European Commission\")\n","models_commission_zinb_5 = run_zinb_by_time(df_commission, \"year_bin_5\", \"European Commission\")\n","models_bundestag_zinb_10 = run_zinb_by_time(df_bundestag, \"year_bin_10\", \"German Bundestag\")\n","models_bundestag_zinb_5 = run_zinb_by_time(df_bundestag, \"year_bin_5\", \"German Bundestag\")\n","\n","\n","def extract_count_params(model):\n","    # Extract parameters for the count model (those not starting with 'inflate_')\n","    return model.params[~model.params.index.str.contains(\"inflate\")]\n","\n","def wald_test_over_time_zinb(models, institution):\n","    test_results = {}\n","    time_combinations = list(combinations(models.keys(), 2))\n","    for (t1, t2) in time_combinations:\n","        model1 = models[t1]\n","        model2 = models[t2]\n","        params1 = extract_count_params(model1)\n","        params2 = extract_count_params(model2)\n","        common_params = list(set(params1.index) & set(params2.index))\n","        if len(common_params) == 0:\n","            continue\n","        diff = params1[common_params] - params2[common_params]\n","        var_diff = model1.bse[common_params]**2 + model2.bse[common_params]**2\n","        wald_stat = sum((diff**2) / var_diff)\n","        df_param = len(common_params)\n","        p_value = 1 - chi2.sf(wald_stat, df=df_param)\n","        test_results[(t1, t2)] = p_value\n","    print(f\"ZINB Wald tests completed for {institution}.\")\n","    return test_results\n","\n","wald_commission_zinb_10 = wald_test_over_time_zinb(models_commission_zinb_10, \"European Commission\")\n","wald_commission_zinb_5 = wald_test_over_time_zinb(models_commission_zinb_5, \"European Commission\")\n","wald_bundestag_zinb_10 = wald_test_over_time_zinb(models_bundestag_zinb_10, \"German Bundestag\")\n","wald_bundestag_zinb_5 = wald_test_over_time_zinb(models_bundestag_zinb_5, \"German Bundestag\")\n","\n","def find_most_similar_periods_zinb(models_commission, models_bundestag):\n","    similarity_results = {}\n","    for comm_time, comm_model in models_commission.items():\n","        best_match = None\n","        min_distance = float(\"inf\")\n","        count_params_comm = extract_count_params(comm_model)\n","        for bund_time, bund_model in models_bundestag.items():\n","            count_params_bund = extract_count_params(bund_model)\n","            common_params = list(set(count_params_comm.index) & set(count_params_bund.index))\n","            if len(common_params) > 0:\n","                distance = euclidean(count_params_comm[common_params], count_params_bund[common_params])\n","                if distance < min_distance:\n","                    min_distance = distance\n","                    best_match = bund_time\n","        similarity_results[comm_time] = best_match\n","    print(\"ZINB similarity analysis completed between European Commission and German Bundestag.\")\n","    return similarity_results\n","\n","similar_periods_zinb_10 = find_most_similar_periods_zinb(models_commission_zinb_10, models_bundestag_zinb_10)\n","similar_periods_zinb_5 = find_most_similar_periods_zinb(models_commission_zinb_5, models_bundestag_zinb_5)\n","\n","# Display the similarity results\n","print(\"ZINB Most similar time periods (10-year bins):\", similar_periods_zinb_10)\n","print(\"ZINB Most similar time periods (5-year bins):\", similar_periods_zinb_5)\n"],"metadata":{"id":"LH6GA_cS_Dr-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.stats import chi2\n","from itertools import combinations\n","\n","def wald_test_sex_effect(models, sex_param=\"C(sex)[T.1]\"):\n","\n","    test_results = {}\n","    time_combinations = list(combinations(models.keys(), 2))\n","    for (t1, t2) in time_combinations:\n","        model1 = models[t1]\n","        model2 = models[t2]\n","        # Check if the sex parameter is in both models\n","        if sex_param in model1.params.index and sex_param in model2.params.index:\n","            beta1 = model1.params[sex_param]\n","            se1 = model1.bse[sex_param]\n","            beta2 = model2.params[sex_param]\n","            se2 = model2.bse[sex_param]\n","            diff = beta1 - beta2\n","            var_diff = se1**2 + se2**2\n","            wald_stat = (diff**2) / var_diff\n","            p_value = 1 - chi2.sf(wald_stat, df=1)\n","            test_results[(t1, t2)] = p_value\n","        else:\n","            test_results[(t1, t2)] = None\n","    return test_results\n","\n","# For example, for the European Commission models:\n","# (If sex is coded as 0/1, the dummy for value 1 is likely \"C(sex)[T.1]\".)\n","wald_commission_sex_10 = wald_test_sex_effect(models_commission_10, sex_param=\"C(sex)[T.1]\")\n","wald_commission_sex_5 = wald_test_sex_effect(models_commission_5, sex_param=\"C(sex)[T.1]\")\n","\n","# For the German Bundestag models:\n","# (If sex is boolean, the dummy might be \"C(sex)[T.True]\". Adjust as needed.)\n","wald_bundestag_sex_10 = wald_test_sex_effect(models_bundestag_10, sex_param=\"C(sex)[T.True]\")\n","wald_bundestag_sex_5 = wald_test_sex_effect(models_bundestag_5, sex_param=\"C(sex)[T.True]\")\n","\n","print(\"Wald tests for sex effect (European Commission, 10-year bins):\", wald_commission_sex_10)\n","print(\"Wald tests for sex effect (European Commission, 5-year bins):\", wald_commission_sex_5)\n","print(\"Wald tests for sex effect (German Bundestag, 10-year bins):\", wald_bundestag_sex_10)\n","print(\"Wald tests for sex effect (German Bundestag, 5-year bins):\", wald_bundestag_sex_5)\n"],"metadata":{"id":"1a5rkYzt_Y8y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.stats import chi2\n","from itertools import combinations\n","\n","def compare_sex_effect_across_institutions(models_commission, models_bundestag,\n","                                           sex_param_comm=\"C(sex)[T.1]\",\n","                                           sex_param_bund=\"C(sex)[T.True]\"):\n","\n","    comparisons = {}\n","    common_bins = set(models_commission.keys()).intersection(set(models_bundestag.keys()))\n","    for time_bin in sorted(common_bins):\n","        mod_comm = models_commission[time_bin]\n","        mod_bund = models_bundestag[time_bin]\n","        if (sex_param_comm in mod_comm.params.index) and (sex_param_bund in mod_bund.params.index):\n","            beta_comm = mod_comm.params[sex_param_comm]\n","            beta_bund = mod_bund.params[sex_param_bund]\n","            se_comm = mod_comm.bse[sex_param_comm]\n","            se_bund = mod_bund.bse[sex_param_bund]\n","            diff = beta_comm - beta_bund\n","            var_diff = se_comm**2 + se_bund**2\n","            if var_diff <= 0:\n","                comparisons[time_bin] = np.nan\n","            else:\n","                wald_stat = (diff**2) / var_diff\n","                p_val = 1 - chi2.sf(wald_stat, df=1)\n","                comparisons[time_bin] = p_val\n","        else:\n","            comparisons[time_bin] = None\n","    return comparisons\n","\n","# Compare the sex effect across institutions for 10-year bins:\n","sex_diff_10 = compare_sex_effect_across_institutions(models_commission_zinb_10,\n","                                                     models_bundestag_zinb_10,\n","                                                     sex_param_comm=\"C(sex)[T.1]\",\n","                                                     sex_param_bund=\"C(sex)[T.True]\")\n","\n","# And for 5-year bins:\n","sex_diff_5 = compare_sex_effect_across_institutions(models_commission_zinb_5,\n","                                                    models_bundestag_zinb_5,\n","                                                    sex_param_comm=\"C(sex)[T.1]\",\n","                                                    sex_param_bund=\"C(sex)[T.True]\")\n","\n","print(\"Wald test p-values for sex effect differences (10-year bins):\", sex_diff_10)\n","print(\"Wald test p-values for sex effect differences (5-year bins):\", sex_diff_5)\n"],"metadata":{"id":"myDS8ayICGri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.stats import chi2\n","from itertools import combinations\n","import numpy as np\n","\n","def compare_sex_effect_logistic(models_comm, models_bund, sex_param_comm=\"C(sex)[T.1]\", sex_param_bund=\"C(sex)[T.True]\"):\n","\n","\n","    comparisons = {}\n","    # Only consider time bins that exist in both dictionaries\n","    common_bins = set(models_comm.keys()).intersection(set(models_bund.keys()))\n","    for time_bin in sorted(common_bins):\n","        mod_comm = models_comm[time_bin]\n","        mod_bund = models_bund[time_bin]\n","        if (sex_param_comm in mod_comm.params.index) and (sex_param_bund in mod_bund.params.index):\n","            beta_comm = mod_comm.params[sex_param_comm]\n","            beta_bund = mod_bund.params[sex_param_bund]\n","            se_comm = mod_comm.bse[sex_param_comm]\n","            se_bund = mod_bund.bse[sex_param_bund]\n","            diff = beta_comm - beta_bund\n","            var_diff = se_comm**2 + se_bund**2\n","            if var_diff <= 0:\n","                comparisons[time_bin] = np.nan\n","            else:\n","                wald_stat = (diff**2) / var_diff\n","                p_val = 1 - chi2.sf(wald_stat, df=1)\n","                comparisons[time_bin] = p_val\n","        else:\n","            comparisons[time_bin] = None\n","    return comparisons\n","\n","# Now, compare the sex effect between the two institutions.\n","# For example, using your 10-year bin logistic models:\n","sex_diff_logistic_10 = compare_sex_effect_logistic(models_commission_10, models_bundestag_10,\n","                                                   sex_param_comm=\"C(sex)[T.1]\",\n","                                                   sex_param_bund=\"C(sex)[T.True]\")\n","\n","# And similarly for the 5-year bins:\n","sex_diff_logistic_5 = compare_sex_effect_logistic(models_commission_5, models_bundestag_5,\n","                                                  sex_param_comm=\"C(sex)[T.1]\",\n","                                                  sex_param_bund=\"C(sex)[T.True]\")\n","\n","print(\"Wald test p-values for sex effect differences (10-year bins):\", sex_diff_logistic_10)\n","print(\"Wald test p-values for sex effect differences (5-year bins):\", sex_diff_logistic_5)\n"],"metadata":{"id":"BVut8aO6DQaT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# # Convert dictionaries to DataFrames\n","df_sim_10 = pd.DataFrame(list(similar_periods_10.items()), columns=[\"EC Period\", \"GB Period\"])\n","df_sim_5 = pd.DataFrame(list(similar_periods_5.items()), columns=[\"EC Period\", \"GB Period\"])\n","\n","# Create pivot tables for heatmap visualization\n","heatmap_10 = df_sim_10.pivot(index=\"EC Period\", columns=\"GB Period\", values=\"EC Period\")\n","heatmap_5 = df_sim_5.pivot(index=\"EC Period\", columns=\"GB Period\", values=\"EC Period\")\n","\n","# Plot heatmap for 10-year bins\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(heatmap_10, annot=True, fmt=\".0f\", cmap=\"Blues\", linewidths=0.5, cbar=True)\n","plt.title(\"Similarity Heatmap (10-Year Bins)\\nEuropean Commission vs. German Bundestag\")\n","plt.xlabel(\"German Bundestag Period\")\n","plt.ylabel(\"European Commission Period\")\n","plt.show()\n","\n","# Plot heatmap for 5-year bins\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(heatmap_5, annot=True, fmt=\".0f\", cmap=\"Oranges\", linewidths=0.5, cbar=True)\n","plt.title(\"Similarity Heatmap (5-Year Bins)\\nEuropean Commission vs. German Bundestag\")\n","plt.xlabel(\"German Bundestag Period\")\n","plt.ylabel(\"European Commission Period\")\n","plt.show()\n"],"metadata":{"id":"huoJDlwPK1rP"},"execution_count":null,"outputs":[]}]}
